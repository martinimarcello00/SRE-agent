{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Tool Sequence Analysis\n",
                "\n",
                "This notebook analyzes the sequence of tool calls in RCA tasks. It ingests experiment results, extracts tool usage patterns, and visualizes the flow of tool calls using a Sankey diagram.\n",
                "\n",
                "**Note**: To export static images (PNG), you need the `kaleido` package installed (`pip install kaleido`)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import json\n",
                "import pandas as pd\n",
                "import plotly.graph_objects as go\n",
                "import plotly.express as px\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "# Load environment variables\n",
                "root_dir = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
                "load_dotenv(os.path.join(root_dir, '.env'))\n",
                "\n",
                "RESULTS_DIR = os.environ.get(\"RESULTS_PATH\")\n",
                "print(f\"Results Directory: {RESULTS_DIR}\")\n",
                "\n",
                "# Output directory for static plots\n",
                "PLOTS_DIR = \"analysis_plots\"\n",
                "os.makedirs(PLOTS_DIR, exist_ok=True)\n",
                "print(f\"Plots will be saved to: {PLOTS_DIR}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Select Experiments"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if RESULTS_DIR and os.path.exists(RESULTS_DIR):\n",
                "    experiment_batches = [d for d in os.listdir(RESULTS_DIR) if os.path.isdir(os.path.join(RESULTS_DIR, d))]\n",
                "    experiment_batches.sort()\n",
                "    \n",
                "    print(\"Available Experiment Batches:\")\n",
                "    for i, d in enumerate(experiment_batches, 1):\n",
                "        dir_path = os.path.join(RESULTS_DIR, d)\n",
                "        json_count = sum(1 for f in os.listdir(dir_path) if f.endswith('.json'))\n",
                "        print(f\"{i}) {d} ({json_count} results)\")\n",
                "else:\n",
                "    print(\"Results directory not found or empty.\")\n",
                "    experiment_batches = []"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Interactive Selection (Default to last if no input mechanism in non-interactive run)\n",
                "selected_indices = input(\"Enter experiment batch IDs (comma-separated, e.g., 1,2): \")\n",
                "\n",
                "selected_dirs = []\n",
                "try:\n",
                "    if selected_indices.strip():\n",
                "        indices = [int(x.strip()) - 1 for x in selected_indices.split(',')]\n",
                "        for idx in indices:\n",
                "            if 0 <= idx < len(experiment_batches):\n",
                "                selected_dirs.append(os.path.join(RESULTS_DIR, experiment_batches[idx]))\n",
                "            else:\n",
                "                print(f\"Warning: Index {idx+1} out of range.\")\n",
                "    else:\n",
                "        print(\"No input provided.\")\n",
                "except ValueError:\n",
                "    print(\"Invalid input.\")\n",
                "\n",
                "if not selected_dirs and experiment_batches:\n",
                "    print(\"Defaulting to the most recent batch.\")\n",
                "    selected_dirs = [os.path.join(RESULTS_DIR, experiment_batches[-1])]\n",
                "    \n",
                "print(f\"Selected {len(selected_dirs)} folders for analysis.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Data Ingestion & Processing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def extract_tool_calls(message_history):\n",
                "    \"\"\"Extracts a sequential list of tool names from message history.\"\"\"\n",
                "    tool_sequence = []\n",
                "    if not isinstance(message_history, list):\n",
                "        return tool_sequence\n",
                "        \n",
                "    for message in message_history:\n",
                "        # Check if message is an AI message with tool calls\n",
                "        if isinstance(message, dict) and message.get(\"type\") == \"AIMessage\":\n",
                "            tool_calls = message.get(\"tool_calls\", [])\n",
                "            for tc in tool_calls:\n",
                "                if isinstance(tc, dict) and \"name\" in tc:\n",
                "                    tool_sequence.append(tc[\"name\"])\n",
                "    return tool_sequence\n",
                "\n",
                "records = []\n",
                "\n",
                "for folder in selected_dirs:\n",
                "    if not os.path.exists(folder):\n",
                "        continue\n",
                "        \n",
                "    files = [f for f in os.listdir(folder) if f.endswith('.json')]\n",
                "    print(f\"Processing {folder}... Found {len(files)} JSON files.\")\n",
                "    \n",
                "    for file_name in files:\n",
                "        file_path = os.path.join(folder, file_name)\n",
                "        try:\n",
                "            with open(file_path, 'r') as f:\n",
                "                data = json.load(f)\n",
                "            \n",
                "            agent_id = data.get(\"agent_id\", \"Unknown\")\n",
                "            app_name = data.get(\"app_name\") or data.get(\"testbed\", {}).get(\"application_name\", [\"Unknown\"])[0]\n",
                "            fault_type = data.get(\"testbed\", {}).get(\"fault_name\", \"Unknown\")\n",
                "            \n",
                "            # Evaluation Data\n",
                "            evaluation = data.get(\"evaluation\", {})\n",
                "            eval_detection = evaluation.get(\"detection\")\n",
                "            eval_localization = evaluation.get(\"localization\")\n",
                "            eval_rca_score = evaluation.get(\"rca_score\")\n",
                "\n",
                "            # Experiment Stats\n",
                "            stats = data.get(\"stats\", {})\n",
                "            execution_time = stats.get(\"execution_time_seconds\")\n",
                "            total_tokens = stats.get(\"total_tokens\")\n",
                "\n",
                "            # Process RCA Analyses\n",
                "            rca_list = data.get(\"rca_analyses_list\", [])\n",
                "            if not rca_list:\n",
                "                continue # Skip if no analysis\n",
                "                \n",
                "            for i, analysis in enumerate(rca_list, 1):\n",
                "                message_history = analysis.get(\"message_history\", [])\n",
                "                tool_sequence = extract_tool_calls(message_history)\n",
                "                \n",
                "                # Create record\n",
                "                row = {\n",
                "                    \"Agent ID\": agent_id,\n",
                "                    \"Application Name\": app_name,\n",
                "                    \"Fault Type\": fault_type,\n",
                "                    \"Eval Detection\": eval_detection,\n",
                "                    \"Eval Localization\": eval_localization,\n",
                "                    \"Eval RCA Score\": eval_rca_score,\n",
                "                    \"Execution Time (s)\": execution_time,\n",
                "                    \"Total Tokens\": total_tokens,\n",
                "                    \"RCA Task Index\": f\"RCA Task {i}\",\n",
                "                    \"Total Tools\": len(tool_sequence)\n",
                "                }\n",
                "                \n",
                "                # Add Tool 1 to Tool 10\n",
                "                for t_idx in range(10):\n",
                "                    col_name = f\"Tool {t_idx + 1}\"\n",
                "                    if t_idx < len(tool_sequence):\n",
                "                        row[col_name] = tool_sequence[t_idx]\n",
                "                    else:\n",
                "                        row[col_name] = None # Or \"End\"\n",
                "                \n",
                "                records.append(row)\n",
                "                \n",
                "        except Exception as e:\n",
                "            print(f\"Error processing {file_name}: {e}\")\n",
                "\n",
                "df = pd.DataFrame(records)\n",
                "print(f\"Created DataFrame with {len(df)} rows.\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Visualization: Tool Sequence Sankey Diagram"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Prepare data for Sankey\n",
                "# We strictly want sequences: Tool 1 -> Tool 2 -> Tool 3 ...\n",
                "\n",
                "# Sources: Index of the source node\n",
                "# Targets: Index of the target node\n",
                "# Values: Count of transitions\n",
                "\n",
                "# To make the Sankey readable (layers), we need unique node names per step.\n",
                "# E.g., \"Step1: get_logs\" is different from \"Step2: get_logs\".\n",
                "\n",
                "max_depth = 10\n",
                "links = []\n",
                "\n",
                "# Initialize node mapping\n",
                "# Format: \"{StepIndex}_{ToolName}\" -> ID\n",
                "node_label_map = {}\n",
                "node_labels = []\n",
                "node_counter = 0\n",
                "\n",
                "def get_node_id(step, tool_name):\n",
                "    global node_counter\n",
                "    label = f\"Step {step}: {tool_name}\"\n",
                "    if label not in node_label_map:\n",
                "        node_label_map[label] = node_counter\n",
                "        node_labels.append(tool_name) # Just show tool name in plot, but ID distinguishes step\n",
                "        node_counter += 1\n",
                "    return node_label_map[label]\n",
                "\n",
                "source_indices = []\n",
                "target_indices = []\n",
                "values = []\n",
                "\n",
                "# Aggregate transitions\n",
                "transitions = {}\n",
                "\n",
                "for _, row in df.iterrows():\n",
                "    # Walk through tools 1 to 10\n",
                "    for i in range(1, max_depth):\n",
                "        current_col = f\"Tool {i}\"\n",
                "        next_col = f\"Tool {i+1}\"\n",
                "        \n",
                "        current_tool = row[current_col]\n",
                "        next_tool = row[next_col]\n",
                "        \n",
                "        # Validate sequence\n",
                "        if pd.isna(current_tool):\n",
                "            break # End of sequence\n",
                "        \n",
                "        if pd.isna(next_tool):\n",
                "            # Transition to \"End\" node for this step\n",
                "            next_tool_label = \"End\"\n",
                "        else:\n",
                "            next_tool_label = next_tool\n",
                "            \n",
                "        # Key: (Step_i, ToolA, Step_i+1, ToolB)\n",
                "        key = (i, current_tool, i+1, next_tool_label)\n",
                "        transitions[key] = transitions.get(key, 0) + 1\n",
                "        \n",
                "        if next_tool_label == \"End\":\n",
                "            break\n",
                "\n",
                "# Build Sankey Arrays\n",
                "for (step_from, tool_from, step_to, tool_to), count in transitions.items():\n",
                "    src_id = get_node_id(step_from, tool_from)\n",
                "    tgt_id = get_node_id(step_to, tool_to)\n",
                "    \n",
                "    source_indices.append(src_id)\n",
                "    target_indices.append(tgt_id)\n",
                "    values.append(count)\n",
                "\n",
                "# Create Plot\n",
                "fig = go.Figure(data=[go.Sankey(\n",
                "    node = dict(\n",
                "      pad = 15,\n",
                "      thickness = 20,\n",
                "      line = dict(color = \"black\", width = 0.5),\n",
                "      label = node_labels,\n",
                "      color = \"blue\"\n",
                "    ),\n",
                "    link = dict(\n",
                "      source = source_indices,\n",
                "      target = target_indices,\n",
                "      value = values\n",
                "  ))])\n",
                "\n",
                "fig.update_layout(title_text=\"Tool Call Sequence Flow (Steps 1-10)\", font_size=10)\n",
                "fig.show()\n",
                "\n",
                "# Save Static Image\n",
                "try:\n",
                "    static_file = os.path.join(PLOTS_DIR, \"tool_sequence_sankey.png\")\n",
                "    fig.write_image(static_file)\n",
                "    print(f\"Saved static Sankey diagram to {static_file}\")\n",
                "except ValueError as e:\n",
                "    print(f\"Could not save static image. Ensure 'kaleido' is installed. Error: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Tool Distribution Analysis\n",
                "\n",
                "Analyzes the frequency of tools used at each specific step."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Distribution of First Tool\n",
                "first_tool_counts = df['Tool 1'].value_counts()\n",
                "fig = px.bar(first_tool_counts, title=\"Distribution of First Tool Called\")\n",
                "fig.show()\n",
                "\n",
                "# Save Static Image\n",
                "try:\n",
                "    static_file = os.path.join(PLOTS_DIR, \"first_tool_distribution.png\")\n",
                "    fig.write_image(static_file)\n",
                "    print(f\"Saved static distribution plot to {static_file}\")\n",
                "except ValueError as e:\n",
                "    print(f\"Could not save static image. Ensure 'kaleido' is installed. Error: {e}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python (SRE Agent)",
            "language": "python",
            "name": "sre-agent"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}