{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6c87674",
   "metadata": {},
   "source": [
    "# SRE Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23547f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# Get the path to the root directory of the repository\n",
    "root_dir = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
    "\n",
    "# Load environment variables from .env file in the root directory\n",
    "load_dotenv(os.path.join(root_dir, '.env'), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac13c533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Add MCP-server to path\n",
    "mcp_server_path = os.path.abspath(os.path.join(os.getcwd(), '../../MCP-server'))\n",
    "sys.path.insert(0, mcp_server_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee32f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "gpt5mini = ChatOpenAI(model=\"gpt-5-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a91c80",
   "metadata": {},
   "source": [
    "## 1. Triage Agent\n",
    "\n",
    "Gather a high-level overview of the cluster's health and identify potential problem areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b2b53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Literal\n",
    "\n",
    "class Symptom(BaseModel):\n",
    "    \"\"\"A symptom observed in the Kubernetes cluster\"\"\"\n",
    "    potential_symptom: str = Field(..., description=\"Type of symptom observed\")\n",
    "    resource_type: Literal[\"pod\", \"service\"] = Field(..., description=\"Type of resource experiencing the issue\")\n",
    "    affected_resource: str = Field(..., description=\"Exact name of the resource experiencing the issue (no namespace or decorators)\")\n",
    "    evidence: str = Field(..., description=\"Evidence supporting this symptom identification\")\n",
    "\n",
    "class SymptomList(BaseModel):\n",
    "    \"\"\"A list of symptoms observed in the Kubernetes cluster\"\"\"\n",
    "    symptoms: List[Symptom] = Field(default_factory=list, description=\"List of symptoms observed in the cluster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2816cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Literal, Annotated\n",
    "\n",
    "class TriageAgentState(TypedDict):\n",
    "    app_name: str\n",
    "    app_summary: str\n",
    "    target_namespace: str\n",
    "    trace_service_starting_point: str\n",
    "    problematic_pods: dict\n",
    "    problematic_traces: dict\n",
    "    slow_traces: dict\n",
    "    problematic_metrics: dict\n",
    "    symptoms: List[Symptom]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7c1e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from api.jaeger_api import JaegerAPI\n",
    "from api.k8s_api import K8sAPI\n",
    "from api.prometheus_api import PrometheusAPI\n",
    "\n",
    "def get_triage_data(state: TriageAgentState):\n",
    "    \"\"\"Get triage data from cluster\"\"\"\n",
    "\n",
    "    jaeger_api = JaegerAPI()\n",
    "    k8s_api = K8sAPI(state[\"target_namespace\"])\n",
    "    prometheus_api = PrometheusAPI(namespace=state[\"target_namespace\"])\n",
    "    \n",
    "    # Get pods with problematic statuses\n",
    "    problematic_pods = k8s_api.get_problematic_pods()\n",
    "\n",
    "    # Traces which have errors\n",
    "    problematic_traces = jaeger_api.get_processed_traces(service=state[\"trace_service_starting_point\"], only_errors=True)\n",
    "\n",
    "    # Filtern for traces whxich take more than 2 seconds\n",
    "    slow_traces = jaeger_api.get_slow_traces(service=state[\"trace_service_starting_point\"], min_duration_ms=2000)\n",
    "\n",
    "    # Metrics with anomalous values\n",
    "    problematic_pods_metrics = {}\n",
    "    problematic_pods_metrics[\"problematic_metrics\"] = []\n",
    "\n",
    "    pods = k8s_api.get_pods_list()\n",
    "\n",
    "    for pod in pods:\n",
    "        triage_metric_report = prometheus_api.get_pod_triage_metrics(pod)\n",
    "        if triage_metric_report[\"is_anomalous\"]:\n",
    "            problematic_pods_metrics[\"problematic_metrics\"].append(triage_metric_report)\n",
    "    \n",
    "    if(len(problematic_pods_metrics[\"problematic_metrics\"])>0):\n",
    "        problematic_pods_metrics[\"pods_count\"] = len(problematic_pods_metrics[\"problematic_metrics\"])\n",
    "    else:\n",
    "        problematic_pods_metrics[\"info\"] = \"All monitored metrics look healthy; no anomalous values detected.\"\n",
    "\n",
    "    return {\n",
    "        \"problematic_pods\": problematic_pods,\n",
    "        \"problematic_traces\": problematic_traces,\n",
    "        \"slow_traces\": slow_traces,\n",
    "        \"problematic_metrics\": problematic_pods_metrics\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a33220",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class Symptom(BaseModel):\n",
    "    \"\"\"\n",
    "    A symptom observed in the Kubernetes cluster\n",
    "    \"\"\"\n",
    "    potential_symptom: str = Field(..., description=\"Type of symptom observed\")\n",
    "    resource_type: Literal[\"pod\", \"service\"] = Field(..., description=\"Type of resource experiencing the issue\")\n",
    "    affected_resource: str = Field(..., description=\"Name of the resource experiencing the issue\")\n",
    "    evidence: str = Field(..., description=\"Evidence supporting this symptom identification\")\n",
    "\n",
    "class SymptomList(BaseModel):\n",
    "    \"\"\"\n",
    "    A list of symptoms observed in the Kubernetes cluster\n",
    "    \"\"\"\n",
    "    symptoms: List[Symptom] = Field(default_factory=list, description=\"List of symptoms observed in the cluster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec98bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_for_symptoms = gpt5mini.with_structured_output(SymptomList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4ebc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "app_summary = \"The application is a hotel reservation system with a microservices architecture. The 'frontend' service is the entry point for user requests.\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are an expert Site Reliability Engineer. Your mission is to triage a Kubernetes application by analyzing the provided data.\n",
    "\n",
    "Your analysis must adhere to the following rules:\n",
    "1.  **Focus**: Identify symptoms at the **pod or service level only**. Do not provide cluster-wide analysis or generalizations.\n",
    "2.  **Aggregation**: For each pod or service that has issues, create **at most one symptom entry**. Aggregate all related evidence (from pods, metrics, traces) into that single entry.\n",
    "3.  **Action**: Synthesize the information to identify and list potential symptoms. For each symptom, pinpoint the affected resource (pod or service) and cite the specific evidence.\n",
    "4.  **Empty State**: If the provided data contains no issues, it is correct to return an empty list of symptoms.\"\"\",\n",
    "        ),\n",
    "        (\"human\", \"{human_input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1b97c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triage_agent(state: TriageAgentState):\n",
    "    human_prompt_parts = [\n",
    "    f\"Please analyze the following triage data for the {state[\"app_name\"]} application.\\n\\n### Application Summary\\n{state[\"app_summary\"]}\"\n",
    "    ]\n",
    "\n",
    "    if \"info\" not in state[\"problematic_pods\"]:\n",
    "        problematic_pods_str = json.dumps(state[\"problematic_pods\"], indent=2)\n",
    "        human_prompt_parts.append(f\"### Problematic Pods\\n```json\\n{problematic_pods_str}\\n```\")\n",
    "\n",
    "    if \"info\" not in state[\"problematic_metrics\"]:\n",
    "        problematic_metrics_str = json.dumps(state[\"problematic_metrics\"], indent=2)\n",
    "        human_prompt_parts.append(f\"### Anomalous Pod Metrics\\n```json\\n{problematic_metrics_str}\\n```\")\n",
    "\n",
    "    if \"info\" not in state[\"problematic_traces\"] and \"error\" not in state[\"problematic_traces\"]:\n",
    "        problematic_traces_str = json.dumps(state[\"problematic_traces\"], indent=2)\n",
    "        human_prompt_parts.append(f\"### Error Traces\\n```json\\n{problematic_traces_str}\\n```\")\n",
    "\n",
    "    if \"info\" not in state[\"slow_traces\"] and \"error\" not in state[\"slow_traces\"]:\n",
    "        slow_traces_str = json.dumps(state[\"slow_traces\"], indent=2)\n",
    "        human_prompt_parts.append(f\"### Slow Traces\\n```json\\n{slow_traces_str}\\n```\")\n",
    "    \n",
    "    # If no problems were found in any dataset, add a note.\n",
    "    if len(human_prompt_parts) == 1:\n",
    "        human_prompt_parts.append(\"No issues were found in pods, metrics, or traces.\")\n",
    "\n",
    "    human_input = \"\\n\\n\".join(human_prompt_parts)\n",
    "\n",
    "    triage_chain = prompt_template | llm_for_symptoms\n",
    "\n",
    "    symptom_list = triage_chain.invoke({\n",
    "        \"human_input\" : human_input\n",
    "    })\n",
    "\n",
    "    return {\"symptoms\" : symptom_list.symptoms} #type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d26c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END, StateGraph\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Build the graph\n",
    "builder = StateGraph(TriageAgentState)\n",
    "\n",
    "# Add nodes\n",
    "builder.add_node(\"gather-triage-data\", get_triage_data)\n",
    "builder.add_node(\"triage-agent\", triage_agent)\n",
    "\n",
    "# Add edges\n",
    "builder.add_edge(START,\"gather-triage-data\")\n",
    "builder.add_edge(\"gather-triage-data\", \"triage-agent\")\n",
    "builder.add_edge(\"triage-agent\", END)\n",
    "\n",
    "triage_agent_graph = builder.compile().with_config(run_name=\"Triage Agent\")\n",
    "\n",
    "display(Image(triage_agent_graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e011d76f",
   "metadata": {},
   "source": [
    "## 2. Planner agent\n",
    "\n",
    "The Planner Agent acts as the strategic core of the RCA workflow. It receives all identified symptoms from the Triage Agent and performs a holistic analysis to identify correlations and potential causal links. Based on this analysis, it generates a unified, de-duplicated, and prioritized investigation plan, which is then distributed to parallel RCA Workers for execution. This centralized planning step transforms the diagnostic process from a reactive to a strategic operation, significantly improving efficiency and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf18241",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RCATask(BaseModel):\n",
    "    \"\"\"A RCA task to be performed by the RCA agent\"\"\"\n",
    "    investigation_goal: str = Field(..., description=\"Goal of the investigation\")\n",
    "    target_resource: str = Field(..., description=\"Name of the resource to investigate\")\n",
    "    resource_type: Literal[\"pod\", \"service\"] = Field(..., description=\"Type of resource being investigated\")\n",
    "    suggested_tools: List[str] = Field(default_factory=list, description=\"List of tools suggested for the investigation\")\n",
    "\n",
    "class RCATaskList(BaseModel):\n",
    "    \"A list of RCA tasks o be performed by the RCA agent in parallel\"\n",
    "    rca_tasks: List[RCATask] = Field(default_factory=list, description=\"List of RCA tasks to be performed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d511d90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Literal, Annotated\n",
    "\n",
    "class PlannerAgentState(TypedDict):\n",
    "    app_name: str\n",
    "    app_summary: str\n",
    "    target_namespace: str\n",
    "    symptoms: List[Symptom]\n",
    "    rca_tasks: List[RCATask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4896f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from api.k8s_api import K8sAPI\n",
    "from api.datagraph import DataGraph\n",
    "\n",
    "def get_resource_dependencies(symptom: Symptom) -> dict:\n",
    "\n",
    "    result = {}\n",
    "    result[\"resource_name\"] = symptom.affected_resource\n",
    "    result[\"resource_type\"] = symptom.resource_type\n",
    "\n",
    "    service = \"\"\n",
    "\n",
    "    k8s_api = K8sAPI()\n",
    "\n",
    "    if symptom.resource_type == \"pod\":\n",
    "        services = k8s_api.get_services_from_pod(symptom.affected_resource)\n",
    "        service =  services[\"services\"][0][\"service_name\"]\n",
    "    else:\n",
    "        service = symptom.affected_resource\n",
    "\n",
    "    datagraph = DataGraph()\n",
    "    \n",
    "    data_dependencies = datagraph.get_services_used_by(service)\n",
    "    infra_dependencies = datagraph.get_dependencies(service)\n",
    "\n",
    "    if len(data_dependencies) > 0:\n",
    "        result[\"data_dependencies\"] = []\n",
    "        for dep in data_dependencies:\n",
    "            temp = {}\n",
    "            temp[\"service\"] = dep\n",
    "            pods = k8s_api.get_pods_from_service(dep)\n",
    "            temp[\"pods\"] = []\n",
    "            for pod in pods[\"pods\"]:\n",
    "                temp[\"pods\"].append(pod[\"pod_name\"])\n",
    "            result[\"data_dependencies\"].append(temp)\n",
    "\n",
    "    if isinstance(infra_dependencies, dict) and len(infra_dependencies) > 0:\n",
    "        result[\"infra_dependencies\"] = []\n",
    "        for dep_name, dep_type in infra_dependencies.items():\n",
    "            dep = {}\n",
    "            dep[\"service\"] = dep_name\n",
    "            dep[\"dependency_type\"] = dep_type\n",
    "            dep[\"pods\"] = []\n",
    "            pods = k8s_api.get_pods_from_service(dep_name)\n",
    "            for pod in pods[\"pods\"]:\n",
    "                dep[\"pods\"].append(pod[\"pod_name\"])\n",
    "            result[\"infra_dependencies\"].append(dep)   \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293a10a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_for_tasks = gpt5mini.with_structured_output(RCATaskList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbe87bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "planner_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are an expert Site Reliability Engineer planning RCA investigations.\n",
    "\n",
    "Your task is to analyze identified symptoms and create a list of RCA tasks for parallel execution.\n",
    "\n",
    "**Available Tools:**\n",
    "\n",
    "*Kubernetes Inspection:*\n",
    "- kubectl_get: Get/list Kubernetes resources\n",
    "- kubectl_describe: Describe resource details\n",
    "- get_pods_from_service: Get pods belonging to a service\n",
    "- get_cluster_pods_and_services: Get cluster overview\n",
    "\n",
    "*Observability & Dependencies:*\n",
    "- get_logs: Retrieve pod/service logs\n",
    "- get_traces: Get traces with error filtering\n",
    "- get_trace: Get detailed trace by ID\n",
    "- get_metrics: Get current metrics (CPU, memory, network)\n",
    "- get_metrics_range: Get historical metrics\n",
    "- get_services_used_by: Get downstream service dependencies\n",
    "- get_dependencies: Get infrastructure dependencies (databases, etc.)\n",
    "\n",
    "**Guidelines:**\n",
    "1. Each task should target ONE specific resource and investigation area\n",
    "2. Suggest tools most likely to reveal the root cause based on symptom type\n",
    "3. De-duplicate: if multiple symptoms share a resource, investigate that resource ONCE\n",
    "4. Prioritize by likelihood of revealing root cause:\n",
    "   - Pod crashes/errors → get_logs, kubectl_describe, get_metrics\n",
    "   - High latency → get_traces, get_services_used_by, get_metrics\n",
    "   - Connectivity issues → get_services_used_by, get_dependencies, kubectl_describe\n",
    "\n",
    "**Task Format:**\n",
    "- investigation_goal: Clear, specific goal (what to investigate and why)\n",
    "- target_resource: The specific resource name (ONLY the exact name, no namespace or other prefixes)\n",
    "- resource_type: \"pod\" or \"service\"\n",
    "- suggested_tools: List of relevant tools (start with most impactful)\n",
    "\n",
    "**IMPORTANT: Resource Names**\n",
    "- Provide ONLY the exact resource name in `target_resource`\n",
    "- Do NOT include namespace prefix (e.g., use \"geo-6b4b89b5f5-rsrh7\" NOT \"test-hotel-reservation/geo-6b4b89b5f5-rsrh7\")\n",
    "- Do NOT include any other qualifiers or decorations\n",
    "\"\"\",\n",
    "        ),\n",
    "        (\"human\", \"{human_input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d823c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def planner_agent(state: PlannerAgentState):\n",
    "    \"\"\"Create RCA investigation tasks from symptoms and their dependencies\"\"\"\n",
    "    \n",
    "    symptoms = state[\"symptoms\"]\n",
    "    \n",
    "    if not symptoms:\n",
    "        return {\"rca_tasks\": []}\n",
    "    \n",
    "    # Enrich symptoms with dependencies\n",
    "    enriched_symptoms = []\n",
    "    for symptom in symptoms:\n",
    "        enriched = {\n",
    "            \"symptom\": symptom.model_dump(),\n",
    "            \"dependencies\": get_resource_dependencies(symptom)\n",
    "        }\n",
    "        enriched_symptoms.append(enriched)\n",
    "    \n",
    "    # Build human prompt with all symptom information in markdown format\n",
    "    human_parts = []\n",
    "    human_parts.append(f\"# Application Context\\n\\n\")\n",
    "    human_parts.append(f\"- **Application**: {state['app_name']}\\n\")\n",
    "    human_parts.append(f\"- **Namespace**: `{state['target_namespace']}`\\n\")\n",
    "    human_parts.append(f\"- **Summary**: {state['app_summary']}\\n\\n\")\n",
    "    human_parts.append(\"---\\n\\n\")\n",
    "    human_parts.append(\"# Symptoms to Investigate\\n\\n\")\n",
    "    \n",
    "    for i, enriched in enumerate(enriched_symptoms, 1):\n",
    "        symptom_dict = enriched[\"symptom\"]\n",
    "        deps = enriched[\"dependencies\"]\n",
    "        \n",
    "        human_parts.append(f\"## Symptom {i}\\n\\n\")\n",
    "        human_parts.append(f\"**Type**: {symptom_dict['potential_symptom']}\\n\\n\")\n",
    "        human_parts.append(f\"**Resource**: `{symptom_dict['affected_resource']}` (`{symptom_dict['resource_type']}`)\\n\\n\")\n",
    "        human_parts.append(f\"**Evidence**:\\n{symptom_dict['evidence']}\\n\\n\")\n",
    "        \n",
    "        # Add dependencies if they exist\n",
    "        if \"data_dependencies\" in deps and deps[\"data_dependencies\"]:\n",
    "            human_parts.append(f\"**Data Dependencies**:\\n```json\\n{json.dumps(deps['data_dependencies'], indent=2)}\\n```\\n\\n\")\n",
    "        \n",
    "        if \"infra_dependencies\" in deps and deps[\"infra_dependencies\"]:\n",
    "            human_parts.append(f\"**Infrastructure Dependencies**:\\n```json\\n{json.dumps(deps['infra_dependencies'], indent=2)}\\n```\\n\\n\")\n",
    "        \n",
    "        if \"data_dependencies\" not in deps and \"infra_dependencies\" not in deps:\n",
    "            human_parts.append(\"**Dependencies**: None found\\n\\n\")\n",
    "        \n",
    "        human_parts.append(\"---\\n\\n\")\n",
    "    \n",
    "    human_input = \"\".join(human_parts)\n",
    "    \n",
    "    # Create and invoke chain\n",
    "    planner_chain = planner_prompt_template | llm_for_tasks\n",
    "    task_list = planner_chain.invoke({\"human_input\": human_input})\n",
    "    \n",
    "    return {\"rca_tasks\": task_list.rca_tasks} # type: ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8152846",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END, StateGraph\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Build the planner graph\n",
    "builder = StateGraph(PlannerAgentState)\n",
    "builder.add_node(\"planner\", planner_agent)\n",
    "builder.add_edge(START, \"planner\")\n",
    "builder.add_edge(\"planner\", END)\n",
    "\n",
    "planner_agent_graph = builder.compile().with_config(run_name=\"Planner Agent\")\n",
    "\n",
    "\n",
    "\n",
    "# Visualize\n",
    "display(Image(planner_agent_graph.get_graph(xray=True).draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaa0989",
   "metadata": {},
   "source": [
    "## 3. RCA Agent (Worker)\n",
    "\n",
    "This agent acts as a tactical executor within the overall diagnostic workflow. It is not responsible for the full RCA, but for executing a single, specific investigation task (e.g., \"check logs for pod X\") assigned to it by the Planner Agent.\n",
    "\n",
    "It runs in parallel with other workers, uses its tools to gather evidence for its assigned task, and then returns a concise diagnostic report. These reports are then collected and synthesized by the Supervisor Agent to determine the final root cause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac51251c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "\n",
    "mcp_client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"kubernetes\" : {\n",
    "            \"command\": \"npx\",\n",
    "            \"args\": [\"mcp-server-kubernetes\"],\n",
    "            \"transport\": \"stdio\",\n",
    "            \"env\": {\n",
    "                \"ALLOW_ONLY_NON_DESTRUCTIVE_TOOLS\": \"true\"\n",
    "            }\n",
    "        },\n",
    "        \"cluster_api\" : {\n",
    "            \"url\": \"http://localhost:8000/mcp\",\n",
    "            \"transport\": \"streamable_http\"\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "mcp_tools = await mcp_client.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61fd001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools allowed\n",
    "k8s_tools_allowed = [\"kubectl_get\", \"kubectl_describe\", \"explain_resource\", \"list_api_resources\", \"ping\"]\n",
    "custom_tools_allowed = [\"get_metrics\", \"get_metrics_range\", \"get_pods_from_service\", \"get_cluster_pods_and_services\", \"get_services_used_by\", \"get_dependencies\", \"get_logs\", \"get_traces\", \"get_trace\"]\n",
    "\n",
    "tools_allowed = k8s_tools_allowed + custom_tools_allowed\n",
    "\n",
    "tools = []\n",
    "for tool in mcp_tools:\n",
    "    if tool.name in tools_allowed:\n",
    "        tools.append(tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a309020",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import TypedDict, Literal, Annotated, List\n",
    "import operator\n",
    "\n",
    "class RCATask(BaseModel):\n",
    "    \"\"\"A RCA task to be performed by the RCA agent\"\"\"\n",
    "    investigation_goal: str = Field(..., description=\"Goal of the investigation\")\n",
    "    target_resource: str = Field(..., description=\"Name of the resource to investigate\")\n",
    "    resource_type: Literal[\"pod\", \"service\"] = Field(..., description=\"Type of resource being investigated\")\n",
    "    suggested_tools: List[str] = Field(default_factory=list, description=\"List of tools suggested for the investigation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4b722b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langgraph.graph.message import add_messages, AnyMessage\n",
    "\n",
    "class RcaAgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    app_summary: str\n",
    "    rca_task: RCATask\n",
    "    insights: Annotated[list[str], operator.add]\n",
    "    prev_steps: Annotated[list[str], operator.add]\n",
    "    rca_analysis: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a244086",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpdateAgentData(BaseModel):\n",
    "    \"\"\"\n",
    "    Represents a step performed by the SRE agent.\n",
    "    \"\"\"\n",
    "    insight: str = Field(..., description=\"Most important new finding\")\n",
    "    prev_step: str = Field(..., description=\"Concise description of the most recent action taken\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455987f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rca_agent_prompt = \"\"\"\n",
    "    You are an expert DevOps engineer performing Root Cause Analysis on a Kubernetes service.\n",
    "\n",
    "    Service: {app_summary}\n",
    "\n",
    "    Investigation Task:\n",
    "    - **Goal**: {investigation_goal}\n",
    "    - **Target**: {resource_type} named '{target_resource}'\n",
    "    - **Suggested Tools**: {suggested_tools}\n",
    "\n",
    "    Your objective is to ACCOMPLISH the investigation goal by identifying the root cause that directly answers it.\n",
    "\n",
    "    Investigation Context:\n",
    "    *Previous Steps:* {prev_steps}\n",
    "    *Insights:* {insights}\n",
    "\n",
    "    Instructions:\n",
    "    1. Use available tools (kubectl, metrics, logs, traces, dependencies) to investigate the target resource\n",
    "    2. Follow the evidence trail to identify the root cause that explains the investigation goal\n",
    "    3. When you have sufficient evidence, call submit_final_diagnosis with:\n",
    "       - diagnosis: The root cause (must directly address the investigation goal)\n",
    "       - reasoning: How your diagnosis answers the investigation goal\n",
    "\n",
    "    IMPORTANT: Do not submit until your diagnosis directly explains what the investigation goal asked you to determine.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e989bc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarise_prompt = \"\"\"\n",
    "    You are an autonomous SRE agent performing Root Cause Analysis on a Kubernetes incident.\n",
    "\n",
    "    Context:\n",
    "\n",
    "    Previous Insights: \n",
    "    {insights}\n",
    "    \n",
    "    Previous Steps:\n",
    "    {prev_steps}\n",
    "\n",
    "    Below are the latest messages (tool calls and/or tool responses - may include parallel executions):\n",
    "    {last_messages}\n",
    "\n",
    "    Instructions:\n",
    "    1. **Extract the key insight**: Identify the most important NEW finding from all the latest messages that helps diagnose the root cause. Focus on:\n",
    "       - Anomalies or unusual patterns\n",
    "       - Resource states that could cause issues\n",
    "       - Dependencies or relationships discovered\n",
    "       - Error messages or failure indicators\n",
    "       - Patterns across multiple tool responses (in case of parallel calls)\n",
    "       If the tool calls failed or returned no useful data, note this as the insight.\n",
    "    \n",
    "    2. **Describe the actions taken**: Write a concise description of what tools were called and what resources were examined.\n",
    "       Format: \"Checked [resource/metric] using [tool_name]\" (list all tools if multiple parallel calls)\n",
    "       Example for parallel: \"Checked pod logs and dependencies using get_logs and get_dependencies\"\n",
    "\n",
    "    Keep both responses under 150 characters each. Be specific and actionable.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec024f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_insights_str(state):\n",
    "    \"\"\"Return a string with the formatted list of insights gathered during exploration\"\"\"\n",
    "    if len(state[\"insights\"]) > 0:\n",
    "        return \"\\n- \".join([\"\"] + state[\"insights\"])\n",
    "    else:\n",
    "        return \"No insights yet\"\n",
    "    \n",
    "def get_prev_steps_str(state):\n",
    "    \"\"\"Return a string with the formatted list of previous steps performed during exploration\"\"\"\n",
    "    if len(state[\"prev_steps\"]) > 0:\n",
    "        return \"\\n- \".join([\"\"] + state[\"prev_steps\"])\n",
    "    else:\n",
    "        return \"No previous steps yet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b411001",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_strct_output = gpt5mini.with_structured_output(UpdateAgentData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349475ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# Node used to summarise the infos given the latest messages (handles parallel tool calls)\n",
    "async def summarise(state: RcaAgentState):\n",
    "\n",
    "    # Gather all recent messages starting from the last AI message (tool calls)\n",
    "    # and all subsequent tool responses\n",
    "    messages = state[\"messages\"]\n",
    "    last_ai_idx = None\n",
    "    \n",
    "    # Find the last AI message (which contains tool calls)\n",
    "    for i in range(len(messages) - 1, -1, -1):\n",
    "        if isinstance(messages[i], AIMessage):\n",
    "            last_ai_idx = i\n",
    "            break\n",
    "    \n",
    "    # Collect messages from last AI message onwards (to capture all parallel responses)\n",
    "    if last_ai_idx is not None:\n",
    "        last_messages = messages[last_ai_idx:]\n",
    "    else:\n",
    "        last_messages = messages[-2:]  # Fallback to last 2 messages\n",
    "\n",
    "    insights_str = get_insights_str(state)\n",
    "    prev_step_str = get_prev_steps_str(state)\n",
    "\n",
    "    prompt = HumanMessage(content=summarise_prompt.format(\n",
    "        prev_steps = prev_step_str,\n",
    "        insights=insights_str,\n",
    "        last_messages=last_messages))\n",
    "\n",
    "    data = llm_with_strct_output.invoke([prompt])\n",
    "\n",
    "    return {\"insights\" : [data.insight], \"prev_steps\" : [data.prev_step]} #type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cc88b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langgraph.types import Command\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.tools import tool, InjectedToolCallId\n",
    "\n",
    "# Tool used to submit the final response\n",
    "@tool\n",
    "def submit_final_diagnosis(\n",
    "    diagnosis: str, \n",
    "    reasoning: str,\n",
    "    tool_call_id: Annotated[str, InjectedToolCallId]\n",
    ") -> Command:\n",
    "    \"\"\"\n",
    "    Submit the final diagnosis when investigation is complete.\n",
    "    \n",
    "    Args:\n",
    "        diagnosis: The issue you have identified (without fixing it)\n",
    "        reasoning: Your reasoning and thought process behind the diagnosis (keep it concise)\n",
    "    \n",
    "    Returns:\n",
    "        Command to update state and end workflow\n",
    "    \"\"\"\n",
    "    final_response = {\n",
    "        \"diagnosis\" : diagnosis,\n",
    "        \"reasoning\" : reasoning\n",
    "    }\n",
    "    \n",
    "    return Command(\n",
    "        update={\n",
    "            \"rca_analysis\": final_response,\n",
    "            \"messages\": [\n",
    "                ToolMessage(\n",
    "                    content=\"Final diagnosis submitted successfully. Investigation complete.\",\n",
    "                    tool_call_id=tool_call_id\n",
    "                )\n",
    "            ]\n",
    "        },\n",
    "        goto=\"format-output\" # End the loop cycle\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082b1385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the tool for submission to the list of tools (MCP servers)\n",
    "completion_tool = submit_final_diagnosis\n",
    "tools_with_completion = tools + [completion_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ce23a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def rcaAgent(state: RcaAgentState):\n",
    "\n",
    "    insights_str = get_insights_str(state)\n",
    "    prev_step_str = get_prev_steps_str(state)\n",
    "    \n",
    "    # Extract task details\n",
    "    task = state[\"rca_task\"]\n",
    "    suggested_tools_str = \", \".join(task.suggested_tools) if task.suggested_tools else \"Use your best judgment\"\n",
    "\n",
    "    prompt = HumanMessage(content=rca_agent_prompt.format(\n",
    "        prev_steps=prev_step_str, \n",
    "        insights=insights_str, \n",
    "        app_summary=state[\"app_summary\"],\n",
    "        investigation_goal=task.investigation_goal,\n",
    "        resource_type=task.resource_type,\n",
    "        target_resource=task.target_resource,\n",
    "        suggested_tools=suggested_tools_str\n",
    "    ))\n",
    "\n",
    "    llm_with_completion_tools = gpt5mini.bind_tools(tools_with_completion, parallel_tool_calls=False)\n",
    "    return {\"messages\": [llm_with_completion_tools.invoke([prompt])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb26f5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "from collections import Counter\n",
    "\n",
    "def count_tool_calls(messages):\n",
    "    \"\"\"\n",
    "    Plots a bar chart of tool call occurrences by tool name from state['messages'].\n",
    "    \"\"\"\n",
    "    # Extract tool names from ToolMessage objects\n",
    "    tool_calls = []\n",
    "    for msg in messages:\n",
    "\n",
    "        if isinstance(msg, AIMessage):\n",
    "            if hasattr(msg, 'additional_kwargs'):\n",
    "                if \"tool_calls\" in msg.additional_kwargs:\n",
    "                    for call in msg.additional_kwargs['tool_calls']:\n",
    "                        if \"function\" in call:\n",
    "                            if \"name\" in call[\"function\"]:\n",
    "                                tool_calls.append(call[\"function\"][\"name\"])\n",
    "\n",
    "    # Count occurrences\n",
    "    counts = Counter(tool_calls)\n",
    "\n",
    "    return dict(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdadd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def format_response(state: RcaAgentState):\n",
    "\n",
    "    final_report = state[\"rca_analysis\"]\n",
    "    \n",
    "    task = state[\"rca_task\"]\n",
    "    final_report[\"task\"] = {\n",
    "        \"investigation_goal\" : task.investigation_goal,\n",
    "        \"target_resource\" : task.target_resource,\n",
    "        \"resource_type\" : task.resource_type,\n",
    "        \"suggested_tools\" : task.suggested_tools\n",
    "    }\n",
    "    \n",
    "    final_report[\"insights\"] = state[\"insights\"]\n",
    "    final_report[\"steps_performed\"] = state[\"prev_steps\"]\n",
    "    final_report[\"tools_stats\"] = count_tool_calls(state[\"messages\"])\n",
    "\n",
    "    return {\"rca_analysis\" : final_report}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465381f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Build the graph\n",
    "builder = StateGraph(RcaAgentState)\n",
    "\n",
    "# Add nodes\n",
    "builder.add_node(\"rca-agent\", rcaAgent)\n",
    "builder.add_node(\"tools\", ToolNode(tools_with_completion)) # Tool node is executing the tool called in the previous message\n",
    "builder.add_node(\"summarise\", summarise) # Node to reduce the raw data into a schema\n",
    "builder.add_node(\"format-output\", format_response)\n",
    "\n",
    "# Add edges\n",
    "builder.add_edge(START, \"rca-agent\")\n",
    "\n",
    "# Conditional edge from sre-agent\n",
    "builder.add_conditional_edges(\n",
    "    \"rca-agent\",\n",
    "    # Use in the conditional_edge to route to the ToolNode if the last message has tool calls. Otherwise, route to the end.\n",
    "    tools_condition,\n",
    ")\n",
    "\n",
    "# After tools, decide whether to summarise or end\n",
    "def after_tools_condition(state: RcaAgentState):\n",
    "    # If rca analysis is filled, investigation is complete (end of the workflow)\n",
    "    if state.get(\"rca_analysis\") and \"diagnosis\" in state[\"rca_analysis\"] and \"reasoning\" in state[\"rca_analysis\"]:\n",
    "        return \"format-output\"\n",
    "    return \"summarise\"\n",
    "\n",
    "builder.add_conditional_edges(\n",
    "    \"tools\",\n",
    "    after_tools_condition,\n",
    "    {\n",
    "        \"summarise\": \"summarise\",\n",
    "        \"format-output\": \"format-output\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# After summarise, continue investigation (go to rca-agent)\n",
    "builder.add_edge(\"summarise\", \"rca-agent\")\n",
    "builder.add_edge(\"format-output\", END)\n",
    "\n",
    "# Compile the graph, returning only the rca_analysis field\n",
    "rca_agent_graph = builder.compile().with_config(run_name=\"RCA Agent\", output_keys=[\"rca_analysis\"])\n",
    "\n",
    "\n",
    "# Show the graph\n",
    "display(Image(rca_agent_graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d00aafc",
   "metadata": {},
   "source": [
    "## 4. Supervisor Agent\n",
    "\n",
    "The Supervisor Agent is the final decision-making component of the RCA workflow. It receives and aggregates all the individual diagnostic reports from the parallel RCA Workers. Its core objective is to synthesize these fragmented findings, correlate information across different investigation tasks, and formulate a single, comprehensive root cause diagnosis for the entire incident. \n",
    "\n",
    "**TODO**: If the findings are inconclusive, it can also trigger a new planning cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4be01ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinalReport(BaseModel):\n",
    "    \"\"\"The Final report created by the supervisor agent\"\"\"\n",
    "    root_cause: str = Field(..., description=\"The identified root cause of the incident\")\n",
    "    affected_resources: List[str] = Field(..., description=\"List of all resources affected by the incident\")\n",
    "    evidence_summary: str = Field(..., description=\"Summary of evidence from all RCA workers\")\n",
    "    investigation_summary: str = Field(..., description=\"Overview of the investigation process and findings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7acb8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "class SupervisorAgentState(TypedDict):\n",
    "    app_name: str\n",
    "    app_summary: str\n",
    "    symptoms: List[Symptom]\n",
    "    rca_analyses_list: List[dict]\n",
    "    final_report: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453c3143",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "gpt5mini = ChatOpenAI(model=\"gpt-5-mini\")\n",
    "\n",
    "llm_for_final_report = gpt5mini.with_structured_output(FinalReport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9747ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "supervisor_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are an expert Site Reliability Engineer analyzing RCA findings to determine the root cause of an incident.\n",
    "\n",
    "Analyze all symptoms and investigation findings to:\n",
    "1. Identify patterns and correlations across findings\n",
    "2. Determine the primary root cause\n",
    "3. List all affected resources\n",
    "4. Summarize key evidence\n",
    "\n",
    "Provide a clear, specific root cause statement that explains what caused the incident.\"\"\",\n",
    "        ),\n",
    "        (\"human\", \"{human_input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557cc41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervisor_agent(state: SupervisorAgentState):\n",
    "    \"\"\"Analyze all RCA findings and produce final root cause diagnosis\"\"\"\n",
    "    \n",
    "    symptoms = state.get(\"symptoms\", [])\n",
    "    rca_analyses = state.get(\"rca_analyses_list\", [])\n",
    "    app_summary = state.get(\"app_summary\", \"\")\n",
    "    app_name = state.get(\"app_name\", \"\")\n",
    "    \n",
    "    if not rca_analyses and not symptoms:\n",
    "        return {\"final_report\": FinalReport(\n",
    "            root_cause=\"No analysis data available\",\n",
    "            affected_resources=[],\n",
    "            evidence_summary=\"No symptoms or RCA analysis provided\",\n",
    "            investigation_summary=\"Investigation incomplete - insufficient data\"\n",
    "        ).model_dump()}\n",
    "    \n",
    "    # Build human prompt with all investigation data in markdown format\n",
    "    human_parts = []\n",
    "    human_parts.append(f\"# Incident Analysis Summary\\n\\n\")\n",
    "    human_parts.append(f\"- **Application**: {app_name}\\n\")\n",
    "    human_parts.append(f\"- **Summary**: {app_summary}\\n\\n\")\n",
    "    human_parts.append(\"---\\n\\n\")\n",
    "    \n",
    "    # Add symptoms\n",
    "    if symptoms:\n",
    "        human_parts.append(\"# Symptoms Identified\\n\\n\")\n",
    "        for i, symptom in enumerate(symptoms, 1):\n",
    "            human_parts.append(f\"## Symptom {i}\\n\\n\")\n",
    "            human_parts.append(f\"**Type**: {symptom.potential_symptom}\\n\\n\")\n",
    "            human_parts.append(f\"**Resource**: `{symptom.affected_resource}` ({symptom.resource_type})\\n\\n\")\n",
    "            human_parts.append(f\"**Evidence**: {symptom.evidence}\\n\\n\")\n",
    "        human_parts.append(\"---\\n\\n\")\n",
    "    \n",
    "    # Add RCA analysis findings\n",
    "    if rca_analyses:\n",
    "        human_parts.append(\"# RCA Investigation Findings\\n\\n\")\n",
    "        for i, analysis in enumerate(rca_analyses, 1):\n",
    "            human_parts.append(f\"## Investigation {i}\\n\\n\")\n",
    "            human_parts.append(f\"```json\\n{json.dumps(analysis, indent=2)}\\n```\\n\\n\")\n",
    "        human_parts.append(\"---\\n\\n\")\n",
    "    \n",
    "    human_input = \"\".join(human_parts)\n",
    "    human_input += \"\\n\\nBased on all the above information, provide a comprehensive root cause diagnosis.\"\n",
    "    \n",
    "    # Create and invoke chain\n",
    "    supervisor_chain = supervisor_prompt_template | llm_for_final_report\n",
    "    final_report = supervisor_chain.invoke({\"human_input\": human_input})\n",
    "    \n",
    "    return {\"final_report\": final_report.model_dump()} #type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d332b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END, StateGraph\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Build the supervisor graph\n",
    "builder = StateGraph(SupervisorAgentState)\n",
    "builder.add_node(\"supervisor\", supervisor_agent)\n",
    "builder.add_edge(START, \"supervisor\")\n",
    "builder.add_edge(\"supervisor\", END)\n",
    "\n",
    "supervisor_agent_graph = builder.compile().with_config(run_name=\"Supervisor Agent\")\n",
    "\n",
    "# Visualize\n",
    "display(Image(supervisor_agent_graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770c5b23",
   "metadata": {},
   "source": [
    "## SRE Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9457e0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SreParentState(TypedDict):\n",
    "    app_name: str\n",
    "    app_summary: str\n",
    "    target_namespace: str\n",
    "    trace_service_starting_point: str\n",
    "\n",
    "    # Triage Agent\n",
    "    problematic_pods: dict\n",
    "    problematic_traces: dict\n",
    "    slow_traces: dict\n",
    "    problematic_metrics: dict\n",
    "    symptoms: List[Symptom]\n",
    "\n",
    "    # Planner agent\n",
    "    rca_tasks: List[RCATask]\n",
    "\n",
    "    # RCA Worker agent\n",
    "    rca_analysis: dict  # Output from individual RCA agent execution\n",
    "    rca_analyses_list: Annotated[list[dict], operator.add]\n",
    "\n",
    "    # Supervisor agent\n",
    "    final_report: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7753ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Send\n",
    "\n",
    "def rca_router(state: SreParentState) -> List[Send]:\n",
    "    \"\"\"Route to RCA agents for parallel execution, or skip to supervisor if no tasks\"\"\"\n",
    "    rca_tasks = state.get(\"rca_tasks\", [])\n",
    "\n",
    "    if not rca_tasks:\n",
    "        # If no tasks, send only the necessary state to the supervisor\n",
    "        supervisor_input = {\n",
    "            \"app_name\": state.get(\"app_name\"),\n",
    "            \"app_summary\": state.get(\"app_summary\"),\n",
    "            \"symptoms\": state.get(\"symptoms\"),\n",
    "            \"rca_analyses_list\": []\n",
    "        }\n",
    "        return [Send(\"supervisor_agent\", supervisor_input)]\n",
    "    \n",
    "    parallel_rca_calls = []\n",
    "    for task in rca_tasks:\n",
    "        rca_input_state = {\n",
    "            \"app_summary\": state[\"app_summary\"],\n",
    "            \"rca_task\": task,\n",
    "            \"messages\": [],\n",
    "            \"insights\": [],\n",
    "            \"prev_steps\": [],\n",
    "        }\n",
    "        parallel_rca_calls.append(Send(\"rca_agent\", rca_input_state))\n",
    "\n",
    "    return parallel_rca_calls\n",
    "\n",
    "def collect_rca_analyses(state: SreParentState) -> dict:\n",
    "    \"\"\"Collect RCA analysis results from parallel RCA agents\"\"\"\n",
    "    # This function is now a \"reducer\" that aggregates results from parallel runs.\n",
    "    # It is invoked after each parallel branch completes.\n",
    "    # The `Annotated` type hint on `rca_analyses_list` in `SreParentState`\n",
    "    # ensures that the list is correctly aggregated across all branches.\n",
    "    \n",
    "    # We only need to return the new analysis to be added to the list.\n",
    "    # LangGraph handles the aggregation.\n",
    "    rca_analysis = state.get(\"rca_analysis\")\n",
    "    if rca_analysis:\n",
    "        return {\"rca_analyses_list\": [rca_analysis]}\n",
    "    \n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb31890",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(SreParentState)\n",
    "\n",
    "builder.add_node(\"triage_agent\", triage_agent_graph)\n",
    "builder.add_node(\"planner_agent\", planner_agent_graph)\n",
    "builder.add_node(\"rca_agent\", rca_agent_graph)\n",
    "builder.add_node(\"collect_analyses\", collect_rca_analyses)\n",
    "builder.add_node(\"supervisor_agent\", supervisor_agent_graph)\n",
    "\n",
    "builder.add_edge(START, \"triage_agent\")\n",
    "builder.add_edge(\"triage_agent\", \"planner_agent\")\n",
    "\n",
    "# Use rca_router to dynamically send tasks to parallel RCA agents\n",
    "# or skip to supervisor if no tasks\n",
    "builder.add_conditional_edges(\n",
    "    \"planner_agent\", \n",
    "    rca_router,\n",
    "    [\"rca_agent\", \"supervisor_agent\"]\n",
    ")\n",
    "\n",
    "# After RCA agents complete, collect their analyses\n",
    "builder.add_edge(\"rca_agent\", \"collect_analyses\")\n",
    "builder.add_edge(\"collect_analyses\", \"supervisor_agent\")\n",
    "\n",
    "builder.add_edge(\"supervisor_agent\", END)\n",
    "\n",
    "parent_graph = builder.compile()\n",
    "Image(parent_graph.get_graph(xray=True).draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d77fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "async def run_sre_agent(graph, app_name: str, app_summary: str, target_namespace: str, trace_service_starting_point: str, trace_name: str | None = None):\n",
    "    \"\"\"Test the SRE agent workflow\"\"\"\n",
    "    \n",
    "    initial_state = {\n",
    "        \"app_name\": app_name,\n",
    "        \"app_summary\": app_summary,\n",
    "        \"target_namespace\": target_namespace,\n",
    "        \"trace_service_starting_point\": trace_service_starting_point,\n",
    "        \"problematic_pods\": {},\n",
    "        \"problematic_traces\": {},\n",
    "        \"slow_traces\": {},\n",
    "        \"problematic_metrics\": {},\n",
    "        \"symptoms\": [],\n",
    "        \"rca_tasks\": [],\n",
    "        \"rca_analysis\": {},\n",
    "        \"rca_analyses_list\": [],\n",
    "        \"final_report\": {}\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    config = {\"recursion_limit\": 80}\n",
    "    if trace_name:\n",
    "        config[\"run_name\"] = trace_name\n",
    "    \n",
    "    result = await graph.ainvoke(initial_state, config)\n",
    "    \n",
    "    execution_time = time.time() - start_time\n",
    "    \n",
    "    return result, execution_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ca5180",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = input(\"Enter experiment name: \")\n",
    "\n",
    "if experiment_name.strip() == \"\":\n",
    "    experiment_name = \"SRE Agent Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97102447",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_summary = \"\"\"\n",
    "    The application implements a hotel reservation service, build with Go and gRPC. The initial project is extended in several ways, including adding back-end in-memory and persistent databases, adding a recommender system for obtaining hotel recommendations, and adding the functionality to place a hotel reservation. \n",
    "\"\"\"\n",
    "target_namespace = \"test-hotel-reservation\"\n",
    "service_starting_point = \"frontend\"\n",
    "\n",
    "result, exec_time = await run_sre_agent(\n",
    "    graph=parent_graph,\n",
    "    app_name=\"Hotel reservation\",\n",
    "    app_summary=app_summary,\n",
    "    target_namespace=target_namespace,\n",
    "    trace_service_starting_point=service_starting_point,\n",
    "    trace_name=experiment_name\n",
    ")\n",
    "\n",
    "print(f\"\\nExecution time: {exec_time:.2f} seconds\")\n",
    "print(f\"\\nFinal report:\\n{result.get('final_report', {})}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sre-agent-35UqMg2y-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
