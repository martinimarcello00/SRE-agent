{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# SRE Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# Get the path to the root directory of the repository\n",
    "root_dir = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
    "\n",
    "# Load environment variables from .env file in the root directory\n",
    "load_dotenv(os.path.join(root_dir, '.env'), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Add MCP-server to path\n",
    "mcp_server_path = os.path.abspath(os.path.join(os.getcwd(), '../../MCP-server'))\n",
    "sys.path.insert(0, mcp_server_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "gpt5mini = ChatOpenAI(model=\"gpt-5-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## 1. Triage Agent\n",
    "\n",
    "Gather a high-level overview of the cluster's health and identify potential problem areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Literal\n",
    "\n",
    "class Symptom(BaseModel):\n",
    "    \"\"\"A symptom observed in the Kubernetes cluster\"\"\"\n",
    "    potential_symptom: str = Field(..., description=\"Type of symptom observed\")\n",
    "    resource_type: Literal[\"pod\", \"service\"] = Field(..., description=\"Type of resource experiencing the issue\")\n",
    "    affected_resource: str = Field(..., description=\"Exact name of the resource experiencing the issue (no namespace or decorators)\")\n",
    "    evidence: str = Field(..., description=\"Evidence supporting this symptom identification\")\n",
    "\n",
    "class SymptomList(BaseModel):\n",
    "    \"\"\"A list of symptoms observed in the Kubernetes cluster\"\"\"\n",
    "    symptoms: List[Symptom] = Field(default_factory=list, description=\"List of symptoms observed in the cluster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Literal, Annotated\n",
    "\n",
    "class TriageAgentState(TypedDict):\n",
    "    app_name: str\n",
    "    app_summary: str\n",
    "    target_namespace: str\n",
    "    trace_service_starting_point: str\n",
    "    problematic_pods: dict\n",
    "    problematic_traces: dict\n",
    "    slow_traces: dict\n",
    "    problematic_metrics: dict\n",
    "    symptoms: List[Symptom]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from api.jaeger_api import JaegerAPI\n",
    "from api.k8s_api import K8sAPI\n",
    "from api.prometheus_api import PrometheusAPI\n",
    "\n",
    "def get_triage_data(state: TriageAgentState):\n",
    "    \"\"\"Get triage data from cluster\"\"\"\n",
    "\n",
    "    jaeger_api = JaegerAPI()\n",
    "    k8s_api = K8sAPI(state[\"target_namespace\"])\n",
    "    prometheus_api = PrometheusAPI(namespace=state[\"target_namespace\"])\n",
    "    \n",
    "    # Get pods with problematic statuses\n",
    "    problematic_pods = k8s_api.get_problematic_pods()\n",
    "\n",
    "    # Traces which have errors\n",
    "    problematic_traces = jaeger_api.get_processed_traces(service=state[\"trace_service_starting_point\"], only_errors=True)\n",
    "\n",
    "    # Filtern for traces whxich take more than 2 seconds\n",
    "    slow_traces = jaeger_api.get_slow_traces(service=state[\"trace_service_starting_point\"], min_duration_ms=2000)\n",
    "\n",
    "    # Metrics with anomalous values\n",
    "    problematic_pods_metrics = {}\n",
    "    problematic_pods_metrics[\"problematic_metrics\"] = []\n",
    "\n",
    "    pods = k8s_api.get_pods_list()\n",
    "\n",
    "    for pod in pods:\n",
    "        triage_metric_report = prometheus_api.get_pod_triage_metrics(pod)\n",
    "        if triage_metric_report[\"is_anomalous\"]:\n",
    "            problematic_pods_metrics[\"problematic_metrics\"].append(triage_metric_report)\n",
    "    \n",
    "    if(len(problematic_pods_metrics[\"problematic_metrics\"])>0):\n",
    "        problematic_pods_metrics[\"pods_count\"] = len(problematic_pods_metrics[\"problematic_metrics\"])\n",
    "    else:\n",
    "        problematic_pods_metrics[\"info\"] = \"All monitored metrics look healthy; no anomalous values detected.\"\n",
    "\n",
    "    return {\n",
    "        \"problematic_pods\": problematic_pods,\n",
    "        \"problematic_traces\": problematic_traces,\n",
    "        \"slow_traces\": slow_traces,\n",
    "        \"problematic_metrics\": problematic_pods_metrics\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class Symptom(BaseModel):\n",
    "    \"\"\"\n",
    "    A symptom observed in the Kubernetes cluster\n",
    "    \"\"\"\n",
    "    potential_symptom: str = Field(..., description=\"Type of symptom observed\")\n",
    "    resource_type: Literal[\"pod\", \"service\"] = Field(..., description=\"Type of resource experiencing the issue\")\n",
    "    affected_resource: str = Field(..., description=\"Name of the resource experiencing the issue\")\n",
    "    evidence: str = Field(..., description=\"Evidence supporting this symptom identification\")\n",
    "\n",
    "class SymptomList(BaseModel):\n",
    "    \"\"\"\n",
    "    A list of symptoms observed in the Kubernetes cluster\n",
    "    \"\"\"\n",
    "    symptoms: List[Symptom] = Field(default_factory=list, description=\"List of symptoms observed in the cluster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_for_symptoms = gpt5mini.with_structured_output(SymptomList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are an expert Site Reliability Engineer. Your mission is to triage a Kubernetes application by analyzing the provided data.\n",
    "\n",
    "Your analysis must adhere to the following rules:\n",
    "1.  **Focus**: Identify symptoms at the **pod or service level only**. Do not provide cluster-wide analysis or generalizations.\n",
    "2.  **Aggregation**: For each pod or service that has issues, create **at most one symptom entry**. Aggregate all related evidence (from pods, metrics, traces) into that single entry.\n",
    "3.  **Action**: Synthesize the information to identify and list potential symptoms. For each symptom, pinpoint the affected resource (pod or service) and cite the specific evidence.\n",
    "4.  **Resource Naming**: In the `affected_resource` field, provide ONLY the exact resource name without any decorators, prefixes, or namespace qualifiers (e.g., use \"geo-6b4b89b5f5-rsrh7\" NOT \"test-hotel-reservation/geo-6b4b89b5f5-rsrh7\").\n",
    "5.  **Empty State**: If the provided data contains no issues, it is correct to return an empty list of symptoms.\"\"\",\n",
    "        ),\n",
    "        (\"human\", \"{human_input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triage_agent(state: TriageAgentState):\n",
    "    human_prompt_parts = [\n",
    "    f\"Please analyze the following triage data for the {state[\"app_name\"]} application.\\n\\n### Application Summary\\n{state[\"app_summary\"]}\"\n",
    "    ]\n",
    "\n",
    "    if \"info\" not in state[\"problematic_pods\"]:\n",
    "        problematic_pods_str = json.dumps(state[\"problematic_pods\"], indent=2)\n",
    "        human_prompt_parts.append(f\"### Problematic Pods\\n```json\\n{problematic_pods_str}\\n```\")\n",
    "\n",
    "    if \"info\" not in state[\"problematic_metrics\"]:\n",
    "        problematic_metrics_str = json.dumps(state[\"problematic_metrics\"], indent=2)\n",
    "        human_prompt_parts.append(f\"### Anomalous Pod Metrics\\n```json\\n{problematic_metrics_str}\\n```\")\n",
    "\n",
    "    if \"info\" not in state[\"problematic_traces\"] and \"error\" not in state[\"problematic_traces\"]:\n",
    "        problematic_traces_str = json.dumps(state[\"problematic_traces\"], indent=2)\n",
    "        human_prompt_parts.append(f\"### Error Traces\\n```json\\n{problematic_traces_str}\\n```\")\n",
    "\n",
    "    if \"info\" not in state[\"slow_traces\"] and \"error\" not in state[\"slow_traces\"]:\n",
    "        slow_traces_str = json.dumps(state[\"slow_traces\"], indent=2)\n",
    "        human_prompt_parts.append(f\"### Slow Traces\\n```json\\n{slow_traces_str}\\n```\")\n",
    "    \n",
    "    # If no problems were found in any dataset, add a note.\n",
    "    if len(human_prompt_parts) == 1:\n",
    "        human_prompt_parts.append(\"No issues were found in pods, metrics, or traces.\")\n",
    "\n",
    "    human_input = \"\\n\\n\".join(human_prompt_parts)\n",
    "\n",
    "    triage_chain = prompt_template | llm_for_symptoms\n",
    "\n",
    "    symptom_list = triage_chain.invoke({\n",
    "        \"human_input\" : human_input\n",
    "    })\n",
    "\n",
    "    return {\"symptoms\" : symptom_list.symptoms} #type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END, StateGraph\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Build the graph\n",
    "builder = StateGraph(TriageAgentState)\n",
    "\n",
    "# Add nodes\n",
    "builder.add_node(\"gather-triage-data\", get_triage_data)\n",
    "builder.add_node(\"triage-agent\", triage_agent)\n",
    "\n",
    "# Add edges\n",
    "builder.add_edge(START,\"gather-triage-data\")\n",
    "builder.add_edge(\"gather-triage-data\", \"triage-agent\")\n",
    "builder.add_edge(\"triage-agent\", END)\n",
    "\n",
    "triage_agent_graph = builder.compile().with_config(run_name=\"Triage Agent\")\n",
    "\n",
    "display(Image(triage_agent_graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## 2. Planner agent\n",
    "\n",
    "The Planner Agent acts as the strategic core of the RCA workflow. It receives all identified symptoms from the Triage Agent and performs a holistic analysis to identify correlations and potential causal links. Based on this analysis, it generates a unified, de-duplicated, and prioritized investigation plan, which is then distributed to parallel RCA Workers for execution. This centralized planning step transforms the diagnostic process from a reactive to a strategic operation, significantly improving efficiency and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RCATask(BaseModel):\n",
    "    \"\"\"A RCA task to be performed by the RCA agent\"\"\"\n",
    "    investigation_goal: str = Field(..., description=\"Goal of the investigation\")\n",
    "    target_resource: str = Field(..., description=\"Name of the resource to investigate\")\n",
    "    resource_type: Literal[\"pod\", \"service\"] = Field(..., description=\"Type of resource being investigated\")\n",
    "    suggested_tools: List[str] = Field(default_factory=list, description=\"List of tools suggested for the investigation\")\n",
    "\n",
    "class RCATaskList(BaseModel):\n",
    "    \"A list of RCA tasks o be performed by the RCA agent in parallel\"\n",
    "    rca_tasks: List[RCATask] = Field(default_factory=list, description=\"List of RCA tasks to be performed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Literal, Annotated\n",
    "\n",
    "class PlannerAgentState(TypedDict):\n",
    "    app_name: str\n",
    "    app_summary: str\n",
    "    target_namespace: str\n",
    "    symptoms: List[Symptom]\n",
    "    rca_tasks: List[RCATask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from api.k8s_api import K8sAPI\n",
    "from api.datagraph import DataGraph\n",
    "\n",
    "def get_resource_dependencies(symptom: Symptom) -> dict:\n",
    "\n",
    "    result = {}\n",
    "    result[\"resource_name\"] = symptom.affected_resource\n",
    "    result[\"resource_type\"] = symptom.resource_type\n",
    "\n",
    "    service = \"\"\n",
    "\n",
    "    k8s_api = K8sAPI()\n",
    "\n",
    "    if symptom.resource_type == \"pod\":\n",
    "        services = k8s_api.get_services_from_pod(symptom.affected_resource)\n",
    "        service =  services[\"services\"][0][\"service_name\"]\n",
    "    else:\n",
    "        service = symptom.affected_resource\n",
    "\n",
    "    datagraph = DataGraph()\n",
    "    \n",
    "    data_dependencies = datagraph.get_services_used_by(service)\n",
    "    infra_dependencies = datagraph.get_dependencies(service)\n",
    "\n",
    "    if len(data_dependencies) > 0:\n",
    "        result[\"data_dependencies\"] = []\n",
    "        for dep in data_dependencies:\n",
    "            temp = {}\n",
    "            temp[\"service\"] = dep\n",
    "            pods = k8s_api.get_pods_from_service(dep)\n",
    "            temp[\"pods\"] = []\n",
    "            for pod in pods[\"pods\"]:\n",
    "                temp[\"pods\"].append(pod[\"pod_name\"])\n",
    "            result[\"data_dependencies\"].append(temp)\n",
    "\n",
    "    if isinstance(infra_dependencies, dict) and len(infra_dependencies) > 0:\n",
    "        result[\"infra_dependencies\"] = []\n",
    "        for dep_name, dep_type in infra_dependencies.items():\n",
    "            dep = {}\n",
    "            dep[\"service\"] = dep_name\n",
    "            dep[\"dependency_type\"] = dep_type\n",
    "            dep[\"pods\"] = []\n",
    "            pods = k8s_api.get_pods_from_service(dep_name)\n",
    "            for pod in pods[\"pods\"]:\n",
    "                dep[\"pods\"].append(pod[\"pod_name\"])\n",
    "            result[\"infra_dependencies\"].append(dep)   \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_for_tasks = gpt5mini.with_structured_output(RCATaskList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "planner_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are an expert Site Reliability Engineer planning RCA investigations.\n",
    "\n",
    "Your task is to analyze identified symptoms and create a list of RCA tasks for parallel execution.\n",
    "\n",
    "**Available Tools:**\n",
    "\n",
    "*Kubernetes Inspection:*\n",
    "- kubectl_get: Get/list Kubernetes resources\n",
    "- kubectl_describe: Describe resource details\n",
    "- get_pods_from_service: Get pods belonging to a service\n",
    "- get_cluster_pods_and_services: Get cluster overview\n",
    "\n",
    "*Observability & Dependencies:*\n",
    "- get_logs: Retrieve pod/service logs\n",
    "- get_traces: Get traces with error filtering\n",
    "- get_trace: Get detailed trace by ID\n",
    "- get_metrics: Get current metrics (CPU, memory, network)\n",
    "- get_metrics_range: Get historical metrics\n",
    "- get_services_used_by: Get downstream service dependencies\n",
    "- get_dependencies: Get infrastructure dependencies (databases, etc.)\n",
    "\n",
    "**Guidelines:**\n",
    "1. Each task should target ONE specific resource and investigation area\n",
    "2. Suggest tools most likely to reveal the root cause based on symptom type\n",
    "3. De-duplicate: if multiple symptoms share a resource, investigate that resource ONCE\n",
    "4. Prioritize by likelihood of revealing root cause:\n",
    "   - Pod crashes/errors → get_logs, kubectl_describe, get_metrics\n",
    "   - High latency → get_traces, get_services_used_by, get_metrics\n",
    "   - Connectivity issues → get_services_used_by, get_dependencies, kubectl_describe\n",
    "\n",
    "**Task Format:**\n",
    "- investigation_goal: Clear, specific goal (what to investigate and why)\n",
    "- target_resource: The specific resource name (ONLY the exact name, no namespace or other prefixes)\n",
    "- resource_type: \"pod\" or \"service\"\n",
    "- suggested_tools: List of relevant tools (start with most impactful)\n",
    "\n",
    "**IMPORTANT: Resource Names**\n",
    "- Provide ONLY the exact resource name in `target_resource`\n",
    "- Do NOT include namespace prefix (e.g., use \"geo-6b4b89b5f5-rsrh7\" NOT \"test-hotel-reservation/geo-6b4b89b5f5-rsrh7\")\n",
    "- Do NOT include any other qualifiers or decorations\n",
    "\"\"\",\n",
    "        ),\n",
    "        (\"human\", \"{human_input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def planner_agent(state: PlannerAgentState):\n",
    "    \"\"\"Create RCA investigation tasks from symptoms and their dependencies\"\"\"\n",
    "    \n",
    "    symptoms = state[\"symptoms\"]\n",
    "    \n",
    "    if not symptoms:\n",
    "        return {\"rca_tasks\": []}\n",
    "    \n",
    "    # Enrich symptoms with dependencies\n",
    "    enriched_symptoms = []\n",
    "    for symptom in symptoms:\n",
    "        enriched = {\n",
    "            \"symptom\": symptom.model_dump(),\n",
    "            \"dependencies\": get_resource_dependencies(symptom)\n",
    "        }\n",
    "        enriched_symptoms.append(enriched)\n",
    "    \n",
    "    # Build human prompt with all symptom information in markdown format\n",
    "    human_parts = []\n",
    "    human_parts.append(f\"# Application Context\\n\\n\")\n",
    "    human_parts.append(f\"- **Application**: {state['app_name']}\\n\")\n",
    "    human_parts.append(f\"- **Namespace**: `{state['target_namespace']}`\\n\")\n",
    "    human_parts.append(f\"- **Summary**: {state['app_summary']}\\n\\n\")\n",
    "    human_parts.append(\"---\\n\\n\")\n",
    "    human_parts.append(\"# Symptoms to Investigate\\n\\n\")\n",
    "    \n",
    "    for i, enriched in enumerate(enriched_symptoms, 1):\n",
    "        symptom_dict = enriched[\"symptom\"]\n",
    "        deps = enriched[\"dependencies\"]\n",
    "        \n",
    "        human_parts.append(f\"## Symptom {i}\\n\\n\")\n",
    "        human_parts.append(f\"**Type**: {symptom_dict['potential_symptom']}\\n\\n\")\n",
    "        human_parts.append(f\"**Resource**: `{symptom_dict['affected_resource']}` (`{symptom_dict['resource_type']}`)\\n\\n\")\n",
    "        human_parts.append(f\"**Evidence**:\\n{symptom_dict['evidence']}\\n\\n\")\n",
    "        \n",
    "        # Add dependencies if they exist\n",
    "        if \"data_dependencies\" in deps and deps[\"data_dependencies\"]:\n",
    "            human_parts.append(f\"**Data Dependencies**:\\n```json\\n{json.dumps(deps['data_dependencies'], indent=2)}\\n```\\n\\n\")\n",
    "        \n",
    "        if \"infra_dependencies\" in deps and deps[\"infra_dependencies\"]:\n",
    "            human_parts.append(f\"**Infrastructure Dependencies**:\\n```json\\n{json.dumps(deps['infra_dependencies'], indent=2)}\\n```\\n\\n\")\n",
    "        \n",
    "        if \"data_dependencies\" not in deps and \"infra_dependencies\" not in deps:\n",
    "            human_parts.append(\"**Dependencies**: None found\\n\\n\")\n",
    "        \n",
    "        human_parts.append(\"---\\n\\n\")\n",
    "    \n",
    "    human_input = \"\".join(human_parts)\n",
    "    \n",
    "    # Create and invoke chain\n",
    "    planner_chain = planner_prompt_template | llm_for_tasks\n",
    "    task_list = planner_chain.invoke({\"human_input\": human_input})\n",
    "    \n",
    "    return {\"rca_tasks\": task_list.rca_tasks} # type: ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END, StateGraph\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Build the planner graph\n",
    "builder = StateGraph(PlannerAgentState)\n",
    "builder.add_node(\"planner\", planner_agent)\n",
    "builder.add_edge(START, \"planner\")\n",
    "builder.add_edge(\"planner\", END)\n",
    "\n",
    "planner_agent_graph = builder.compile().with_config(run_name=\"Planner Agent\")\n",
    "\n",
    "\n",
    "\n",
    "# Visualize\n",
    "display(Image(planner_agent_graph.get_graph(xray=True).draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## 3. RCA Agent (Worker)\n",
    "\n",
    "This agent acts as a tactical executor within the overall diagnostic workflow. It is not responsible for the full RCA, but for executing a single, specific investigation task (e.g., \"check logs for pod X\") assigned to it by the Planner Agent.\n",
    "\n",
    "It runs in parallel with other workers, uses its tools to gather evidence for its assigned task, and then returns a concise diagnostic report. These reports are then collected and synthesized by the Supervisor Agent to determine the final root cause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "\n",
    "mcp_client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"kubernetes\" : {\n",
    "            \"command\": \"npx\",\n",
    "            \"args\": [\"mcp-server-kubernetes\"],\n",
    "            \"transport\": \"stdio\",\n",
    "            \"env\": {\n",
    "                \"ALLOW_ONLY_NON_DESTRUCTIVE_TOOLS\": \"true\"\n",
    "            }\n",
    "        },\n",
    "        \"cluster_api\" : {\n",
    "            \"url\": \"http://localhost:8000/mcp\",\n",
    "            \"transport\": \"streamable_http\"\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "mcp_tools = await mcp_client.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools allowed\n",
    "k8s_tools_allowed = [\"kubectl_get\", \"kubectl_describe\", \"explain_resource\", \"list_api_resources\", \"ping\"]\n",
    "custom_tools_allowed = [\"get_metrics\", \"get_metrics_range\", \"get_pods_from_service\", \"get_cluster_pods_and_services\", \"get_services_used_by\", \"get_dependencies\", \"get_logs\", \"get_traces\", \"get_trace\"]\n",
    "\n",
    "tools_allowed = k8s_tools_allowed + custom_tools_allowed\n",
    "\n",
    "tools = []\n",
    "for tool in mcp_tools:\n",
    "    if tool.name in tools_allowed:\n",
    "        tools.append(tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import TypedDict, Literal, Annotated, List\n",
    "import operator\n",
    "\n",
    "class RCATask(BaseModel):\n",
    "    \"\"\"A RCA task to be performed by the RCA agent\"\"\"\n",
    "    investigation_goal: str = Field(..., description=\"Goal of the investigation\")\n",
    "    target_resource: str = Field(..., description=\"Name of the resource to investigate\")\n",
    "    resource_type: Literal[\"pod\", \"service\"] = Field(..., description=\"Type of resource being investigated\")\n",
    "    suggested_tools: List[str] = Field(default_factory=list, description=\"List of tools suggested for the investigation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langgraph.graph.message import add_messages, AnyMessage\n",
    "\n",
    "class RcaAgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    rca_app_summary: str \n",
    "    rca_target_namespace: str\n",
    "    rca_task: RCATask\n",
    "    insights: Annotated[list[str], operator.add]\n",
    "    prev_steps: Annotated[list[str], operator.add]\n",
    "    rca_output: dict\n",
    "    rca_analyses_list: list[dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpdateAgentData(BaseModel):\n",
    "    \"\"\"\n",
    "    Represents a step performed by the SRE agent.\n",
    "    \"\"\"\n",
    "    insight: str = Field(..., description=\"Most important new finding\")\n",
    "    prev_step: str = Field(..., description=\"Concise description of the most recent action taken\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "rca_agent_prompt = \"\"\"\n",
    "Developer: You are an expert DevOps engineer performing focused Root Cause Analysis on a Kubernetes service.\n",
    "\n",
    "Service: {app_summary}\n",
    "\n",
    "Investigation Task:\n",
    "- **Goal**: {investigation_goal}\n",
    "- **Target**: {resource_type} named '{target_resource}' (namespace {target_namespace})\n",
    "- **Priority Tools**: {suggested_tools}\n",
    "\n",
    "INVESTIGATION BUDGET: Maximum {investigation_budget} tool calls. Use only what is strictly necessary—avoid redundant or unnecessary queries. You have already made **{tool_calls_count}** tool calls out of {investigation_budget}.\n",
    "\n",
    "{budget_status}\n",
    "\n",
    "Investigation Context:\n",
    "*Previous Steps:* {prev_steps}\n",
    "*Insights:* {insights}\n",
    "\n",
    "Instructions:\n",
    "1. Use ONLY the Priority Tools above, which are specifically pre-selected for this investigation. Do not propose or use tools outside this list.\n",
    "2. For each tool call, first formulate a clear, testable hypothesis about a possible root cause that can be answered by the result. Avoid broad or exploratory queries.\n",
    "3. Each tool call must provide unique, non-overlapping information. Never repeat requests with similar parameters or investigate the same aspect repeatedly in slightly different ways.\n",
    "4. Stop investigating, even if you have not reached {investigation_budget} calls, when you have:\n",
    "   - Clear evidence that directly identifies a root cause (or definitively rules one out)\n",
    "   - Multiple data points indicating the same failure/cause\n",
    "   - Sufficient information to answer the investigation goal\n",
    "5. DO NOT:\n",
    "   - Repeat or re-run tools unless you are testing a truly new and justified hypothesis\n",
    "   - Query outside the given Target or Priority Tools\n",
    "   - Investigate unrelated resources or expand scope\n",
    "6. When you have gathered sufficient, non-redundant evidence (typically after 2-3 targeted tool calls), call submit_final_diagnosis with:\n",
    "   - diagnosis: State the precise root cause as it pertains to the investigation goal\n",
    "   - reasoning: Support your diagnosis by referencing unique findings from your tool calls\n",
    "\n",
    "Special constraints:\n",
    "- You will not see the raw results of your tool calls; instead, your summary will be extracted for highlights and steps. Therefore, make each step and summary explicit, clear, and concise.\n",
    "\n",
    "REMEMBER: Quality over quantity. Focus on unique and conclusive findings rather than exhaustive or repetitive investigation.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarise_prompt = \"\"\"\n",
    "    You are an autonomous SRE agent performing Root Cause Analysis on a Kubernetes incident.\n",
    "\n",
    "    Context:\n",
    "\n",
    "    Previous Insights: \n",
    "    {insights}\n",
    "    \n",
    "    Previous Steps:\n",
    "    {prev_steps}\n",
    "\n",
    "    Below are the latest messages (tool calls and/or tool responses - may include parallel executions):\n",
    "    {last_messages}\n",
    "\n",
    "    Instructions:\n",
    "    1. **Extract the key insight**: Identify the most important NEW finding from all the latest messages that helps diagnose the root cause. Focus on:\n",
    "       - Anomalies or unusual patterns\n",
    "       - Resource states that could cause issues\n",
    "       - Dependencies or relationships discovered\n",
    "       - Error messages or failure indicators\n",
    "       - Patterns across multiple tool responses (in case of parallel calls)\n",
    "       If the tool calls failed or returned no useful data, note this as the insight.\n",
    "    \n",
    "    2. **Describe the actions taken**: Write a concise description of what tools were called and what resources were examined.\n",
    "       Format: \"Checked [resource/metric] using [tool_name]\" (list all tools if multiple parallel calls)\n",
    "       Example for parallel: \"Checked pod logs and dependencies using get_logs and get_dependencies\"\n",
    "\n",
    "    Keep both responses under 150 characters each. Be specific and actionable.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_insights_str(state):\n",
    "    \"\"\"Return a string with the formatted list of insights gathered during exploration\"\"\"\n",
    "    if len(state[\"insights\"]) > 0:\n",
    "        return \"\\n- \".join([\"\"] + state[\"insights\"])\n",
    "    else:\n",
    "        return \"No insights yet\"\n",
    "    \n",
    "def get_prev_steps_str(state):\n",
    "    \"\"\"Return a string with the formatted list of previous steps performed during exploration\"\"\"\n",
    "    if len(state[\"prev_steps\"]) > 0:\n",
    "        return \"\\n- \".join([\"\"] + state[\"prev_steps\"])\n",
    "    else:\n",
    "        return \"No previous steps yet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_strct_output = gpt5mini.with_structured_output(UpdateAgentData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# Node used to summarise the infos given the latest messages (handles parallel tool calls)\n",
    "async def summarise(state: RcaAgentState):\n",
    "\n",
    "    # Gather all recent messages starting from the last AI message (tool calls)\n",
    "    # and all subsequent tool responses\n",
    "    messages = state[\"messages\"]\n",
    "    last_ai_idx = None\n",
    "    \n",
    "    # Find the last AI message (which contains tool calls)\n",
    "    for i in range(len(messages) - 1, -1, -1):\n",
    "        if isinstance(messages[i], AIMessage):\n",
    "            last_ai_idx = i\n",
    "            break\n",
    "    \n",
    "    # Collect messages from last AI message onwards (to capture all parallel responses)\n",
    "    if last_ai_idx is not None:\n",
    "        last_messages = messages[last_ai_idx:]\n",
    "    else:\n",
    "        last_messages = messages[-2:]  # Fallback to last 2 messages\n",
    "\n",
    "    insights_str = get_insights_str(state)\n",
    "    prev_step_str = get_prev_steps_str(state)\n",
    "\n",
    "    prompt = HumanMessage(content=summarise_prompt.format(\n",
    "        prev_steps = prev_step_str,\n",
    "        insights=insights_str,\n",
    "        last_messages=last_messages))\n",
    "\n",
    "    data = llm_with_strct_output.invoke([prompt])\n",
    "\n",
    "    return {\"insights\" : [data.insight], \"prev_steps\" : [data.prev_step]} #type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langgraph.types import Command\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.tools import tool, InjectedToolCallId\n",
    "\n",
    "# Tool used to submit the final response\n",
    "@tool\n",
    "def submit_final_diagnosis(\n",
    "    diagnosis: str, \n",
    "    reasoning: str,\n",
    "    tool_call_id: Annotated[str, InjectedToolCallId]\n",
    ") -> Command:\n",
    "    \"\"\"\n",
    "    Submit the final diagnosis when investigation is complete.\n",
    "    \n",
    "    Args:\n",
    "        diagnosis: The issue you have identified (without fixing it)\n",
    "        reasoning: Your reasoning and thought process behind the diagnosis (keep it concise)\n",
    "    \n",
    "    Returns:\n",
    "        Command to update state and end workflow\n",
    "    \"\"\"\n",
    "    final_response = {\n",
    "        \"diagnosis\" : diagnosis,\n",
    "        \"reasoning\" : reasoning\n",
    "    }\n",
    "    \n",
    "    return Command(\n",
    "        update={\n",
    "            \"rca_output\": final_response,\n",
    "            \"messages\": [\n",
    "                ToolMessage(\n",
    "                    content=\"Final diagnosis submitted successfully. Investigation complete.\",\n",
    "                    tool_call_id=tool_call_id\n",
    "                )\n",
    "            ]\n",
    "        },\n",
    "        goto=\"format-output\" # End the loop cycle\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the tool for submission to the list of tools (MCP servers)\n",
    "completion_tool = submit_final_diagnosis\n",
    "tools_with_completion = tools + [completion_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def rcaAgent(state: RcaAgentState):\n",
    "    \n",
    "    # Count tool calls (excluding submit_final_diagnosis) [Budget enforcement]\n",
    "    tool_call_count = 0\n",
    "    for msg in state[\"messages\"]:\n",
    "        if isinstance(msg, AIMessage) and hasattr(msg, 'additional_kwargs'):\n",
    "            if \"tool_calls\" in msg.additional_kwargs:\n",
    "                for call in msg.additional_kwargs.get('tool_calls', []):\n",
    "                    if \"function\" in call:\n",
    "                        tool_name = call.get(\"function\", {}).get(\"name\", \"\")\n",
    "                        if tool_name != \"submit_final_diagnosis\":\n",
    "                            tool_call_count += 1\n",
    "    \n",
    "    MAX_TOOL_CALLS = int(os.environ.get(\"MAX_TOOL_CALLS\", 8))\n",
    "\n",
    "    insights_str = get_insights_str(state)\n",
    "    prev_step_str = get_prev_steps_str(state)\n",
    "    \n",
    "    # Extract task details\n",
    "    task = state[\"rca_task\"]\n",
    "    suggested_tools_str = \", \".join(task.suggested_tools) if task.suggested_tools else \"Use your best judgment\"\n",
    "\n",
    "    # Build budget status message\n",
    "    budget_status = \"\"\n",
    "    if tool_call_count >= MAX_TOOL_CALLS:\n",
    "        budget_status = f\"\"\"\n",
    "⚠️ **BUDGET EXCEEDED**: You have made {tool_call_count}/{MAX_TOOL_CALLS} tool calls.\n",
    "\n",
    "You MUST now call submit_final_diagnosis with your best conclusion based on the evidence gathered so far.\n",
    "Do NOT make any more tool calls. Submit your diagnosis immediately.\n",
    "\"\"\"\n",
    "    elif tool_call_count >= MAX_TOOL_CALLS - 2:\n",
    "        budget_status = f\"\"\"\n",
    "⚠️ **BUDGET WARNING**: You have made {tool_call_count}/{MAX_TOOL_CALLS} tool calls. You should prepare to submit your diagnosis soon.\n",
    "\"\"\"\n",
    "\n",
    "    prompt = HumanMessage(content=rca_agent_prompt.format(\n",
    "        prev_steps=prev_step_str, \n",
    "        insights=insights_str, \n",
    "        app_summary=state[\"rca_app_summary\"],  # Updated field name\n",
    "        target_namespace=state[\"rca_target_namespace\"],  # Updated field name\n",
    "        investigation_goal=task.investigation_goal,\n",
    "        resource_type=task.resource_type,\n",
    "        target_resource=task.target_resource,\n",
    "        suggested_tools=suggested_tools_str,\n",
    "        investigation_budget=MAX_TOOL_CALLS,\n",
    "        tool_calls_count=tool_call_count,\n",
    "        budget_status=budget_status\n",
    "    ))\n",
    "\n",
    "    llm_with_completion_tools = gpt5mini.bind_tools(tools_with_completion, parallel_tool_calls=False)\n",
    "    return {\"messages\": [llm_with_completion_tools.invoke([prompt])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "from collections import Counter\n",
    "\n",
    "def count_tool_calls(messages):\n",
    "    \"\"\"\n",
    "    Plots a bar chart of tool call occurrences by tool name from state['messages'].\n",
    "    \"\"\"\n",
    "    # Extract tool names from ToolMessage objects\n",
    "    tool_calls = []\n",
    "    for msg in messages:\n",
    "        if isinstance(msg, AIMessage):\n",
    "            if hasattr(msg, 'additional_kwargs'):\n",
    "                if \"tool_calls\" in msg.additional_kwargs:\n",
    "                    for call in msg.additional_kwargs['tool_calls']:\n",
    "                        if \"function\" in call:\n",
    "                            if \"name\" in call[\"function\"]:\n",
    "                                tool_calls.append(call[\"function\"][\"name\"])\n",
    "\n",
    "    # Count occurrences\n",
    "    counts = Counter(tool_calls)\n",
    "\n",
    "    return dict(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def format_response(state: RcaAgentState):\n",
    "\n",
    "    final_report = state[\"rca_output\"]\n",
    "    \n",
    "    task = state[\"rca_task\"]\n",
    "    final_report[\"task\"] = {\n",
    "        \"investigation_goal\" : task.investigation_goal,\n",
    "        \"target_resource\" : task.target_resource,\n",
    "        \"resource_type\" : task.resource_type,\n",
    "        \"suggested_tools\" : task.suggested_tools\n",
    "    }\n",
    "    \n",
    "    final_report[\"insights\"] = state[\"insights\"]\n",
    "    final_report[\"steps_performed\"] = state[\"prev_steps\"]\n",
    "    final_report[\"tools_stats\"] = count_tool_calls(state[\"messages\"])\n",
    "\n",
    "    return {\"rca_analyses_list\" : [final_report]}  # Return as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Build the graph\n",
    "builder = StateGraph(RcaAgentState)\n",
    "\n",
    "# Add nodes\n",
    "builder.add_node(\"rca-agent\", rcaAgent)\n",
    "builder.add_node(\"tools\", ToolNode(tools_with_completion)) # Tool node is executing the tool called in the previous message\n",
    "builder.add_node(\"summarise\", summarise) # Node to reduce the raw data into a schema\n",
    "builder.add_node(\"format-output\", format_response)\n",
    "\n",
    "# Add edges\n",
    "builder.add_edge(START, \"rca-agent\")\n",
    "\n",
    "# Conditional edge from sre-agent\n",
    "builder.add_conditional_edges(\n",
    "    \"rca-agent\",\n",
    "    # Use in the conditional_edge to route to the ToolNode if the last message has tool calls. Otherwise, route to the end.\n",
    "    tools_condition,\n",
    ")\n",
    "\n",
    "# After tools, decide whether to summarise or end\n",
    "def after_tools_condition(state: RcaAgentState):\n",
    "    # If rca_analyses_list is filled, investigation is complete (end of the workflow)\n",
    "    if state.get(\"rca_analyses_list\") and len(state[\"rca_analyses_list\"]) > 0:\n",
    "        analysis = state[\"rca_analyses_list\"][0]\n",
    "        if \"diagnosis\" in analysis and \"reasoning\" in analysis:\n",
    "            return \"format-output\"\n",
    "    return \"summarise\"\n",
    "\n",
    "builder.add_conditional_edges(\n",
    "    \"tools\",\n",
    "    after_tools_condition,\n",
    "    {\n",
    "        \"summarise\": \"summarise\",\n",
    "        \"format-output\": \"format-output\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# After summarise, continue investigation (go to rca-agent)\n",
    "builder.add_edge(\"summarise\", \"rca-agent\")\n",
    "builder.add_edge(\"format-output\", END)\n",
    "\n",
    "# Compile the graph, returning only the rca_analyses_list field\n",
    "rca_agent_graph = builder.compile().with_config(run_name=\"RCA Agent\", output_keys=[\"rca_analyses_list\"])\n",
    "\n",
    "\n",
    "# Show the graph\n",
    "display(Image(rca_agent_graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "## 4. Supervisor Agent\n",
    "\n",
    "The Supervisor Agent is the final decision-making component of the RCA workflow. It receives and aggregates all the individual diagnostic reports from the parallel RCA Workers. Its core objective is to synthesize these fragmented findings, correlate information across different investigation tasks, and formulate a single, comprehensive root cause diagnosis for the entire incident. \n",
    "\n",
    "**TODO**: If the findings are inconclusive, it can also trigger a new planning cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinalReport(BaseModel):\n",
    "    \"\"\"The Final report created by the supervisor agent\"\"\"\n",
    "    root_cause: str = Field(..., description=\"The identified root cause of the incident\")\n",
    "    affected_resources: List[str] = Field(..., description=\"List of all resources affected by the incident\")\n",
    "    evidence_summary: str = Field(..., description=\"Summary of evidence from all RCA workers\")\n",
    "    investigation_summary: str = Field(..., description=\"Overview of the investigation process and findings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "class SupervisorAgentState(TypedDict):\n",
    "    app_name: str\n",
    "    app_summary: str\n",
    "    symptoms: List[Symptom]\n",
    "    rca_analyses_list: List[dict]\n",
    "    final_report: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "gpt5mini = ChatOpenAI(model=\"gpt-5-mini\")\n",
    "\n",
    "llm_for_final_report = gpt5mini.with_structured_output(FinalReport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "supervisor_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are an expert Site Reliability Engineer analyzing RCA findings to determine the root cause of an incident.\n",
    "\n",
    "Analyze all symptoms and investigation findings to:\n",
    "1. Identify patterns and correlations across findings\n",
    "2. Determine the primary root cause\n",
    "3. List all affected resources\n",
    "4. Summarize key evidence\n",
    "\n",
    "Provide a clear, specific root cause statement that explains what caused the incident.\"\"\",\n",
    "        ),\n",
    "        (\"human\", \"{human_input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervisor_agent(state: SupervisorAgentState):\n",
    "    \"\"\"Analyze all RCA findings and produce final root cause diagnosis\"\"\"\n",
    "    \n",
    "    symptoms = state.get(\"symptoms\", [])\n",
    "    rca_analyses = state.get(\"rca_analyses_list\", [])\n",
    "    app_summary = state.get(\"app_summary\", \"\")\n",
    "    app_name = state.get(\"app_name\", \"\")\n",
    "    \n",
    "    if not rca_analyses and not symptoms:\n",
    "        return {\"final_report\": FinalReport(\n",
    "            root_cause=\"No analysis data available\",\n",
    "            affected_resources=[],\n",
    "            evidence_summary=\"No symptoms or RCA analysis provided\",\n",
    "            investigation_summary=\"Investigation incomplete - insufficient data\"\n",
    "        ).model_dump()}\n",
    "    \n",
    "    # Build human prompt with all investigation data in markdown format\n",
    "    human_parts = []\n",
    "    human_parts.append(f\"# Incident Analysis Summary\\n\\n\")\n",
    "    human_parts.append(f\"- **Application**: {app_name}\\n\")\n",
    "    human_parts.append(f\"- **Summary**: {app_summary}\\n\\n\")\n",
    "    human_parts.append(\"---\\n\\n\")\n",
    "    \n",
    "    # Add symptoms\n",
    "    if symptoms:\n",
    "        human_parts.append(\"# Symptoms Identified\\n\\n\")\n",
    "        for i, symptom in enumerate(symptoms, 1):\n",
    "            human_parts.append(f\"## Symptom {i}\\n\\n\")\n",
    "            human_parts.append(f\"**Type**: {symptom.potential_symptom}\\n\\n\")\n",
    "            human_parts.append(f\"**Resource**: `{symptom.affected_resource}` ({symptom.resource_type})\\n\\n\")\n",
    "            human_parts.append(f\"**Evidence**: {symptom.evidence}\\n\\n\")\n",
    "        human_parts.append(\"---\\n\\n\")\n",
    "    \n",
    "    # Add RCA analysis findings\n",
    "    if rca_analyses:\n",
    "        human_parts.append(\"# RCA Investigation Findings\\n\\n\")\n",
    "        for i, analysis in enumerate(rca_analyses, 1):\n",
    "            human_parts.append(f\"## Investigation {i}\\n\\n\")\n",
    "            human_parts.append(f\"```json\\n{json.dumps(analysis, indent=2)}\\n```\\n\\n\")\n",
    "        human_parts.append(\"---\\n\\n\")\n",
    "    \n",
    "    human_input = \"\".join(human_parts)\n",
    "    human_input += \"\\n\\nBased on all the above information, provide a comprehensive root cause diagnosis.\"\n",
    "    \n",
    "    # Create and invoke chain\n",
    "    supervisor_chain = supervisor_prompt_template | llm_for_final_report\n",
    "    final_report = supervisor_chain.invoke({\"human_input\": human_input})\n",
    "    \n",
    "    return {\"final_report\": final_report.model_dump()} #type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END, StateGraph\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Build the supervisor graph\n",
    "builder = StateGraph(SupervisorAgentState)\n",
    "builder.add_node(\"supervisor\", supervisor_agent)\n",
    "builder.add_edge(START, \"supervisor\")\n",
    "builder.add_edge(\"supervisor\", END)\n",
    "\n",
    "supervisor_agent_graph = builder.compile().with_config(run_name=\"Supervisor Agent\")\n",
    "\n",
    "# Visualize\n",
    "display(Image(supervisor_agent_graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "## SRE Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SreParentState(TypedDict):\n",
    "    app_name: str\n",
    "    app_summary: str\n",
    "    target_namespace: str\n",
    "    trace_service_starting_point: str\n",
    "\n",
    "    # Triage Agent\n",
    "    problematic_pods: dict\n",
    "    problematic_traces: dict\n",
    "    slow_traces: dict\n",
    "    problematic_metrics: dict\n",
    "    symptoms: List[Symptom]\n",
    "\n",
    "    # Planner agent\n",
    "    rca_tasks: List[RCATask]\n",
    "\n",
    "    # RCA Worker agent\n",
    "    rca_analyses_list: Annotated[list[dict], operator.add]\n",
    "\n",
    "    # Supervisor agent\n",
    "    final_report: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Send\n",
    "import operator  # Ensure operator is imported for Annotated\n",
    "\n",
    "# --- FINAL FIX EXPLANATION ---\n",
    "# Each parallel RCA agent returns {\"rca_analyses_list\": [analysis]} (a list with one analysis).\n",
    "# The parent state aggregates these lists using operator.add, combining all analyses into rca_analyses_list.\n",
    "# This ensures proper parallel execution without InvalidUpdateError.\n",
    "\n",
    "# --- FIXED CODE ---\n",
    "def rca_router(state: SreParentState) -> list[Send]:\n",
    "    \"\"\"Route to RCA agents for parallel execution, or skip to supervisor if no tasks\"\"\"\n",
    "    rca_tasks = state.get(\"rca_tasks\", [])\n",
    "\n",
    "    if not rca_tasks:\n",
    "        # No RCA tasks, go directly to supervisor with current symptoms\n",
    "        supervisor_input = {\n",
    "            \"app_name\": state.get(\"app_name\"),\n",
    "            \"app_summary\": state.get(\"app_summary\"),\n",
    "            \"symptoms\": state.get(\"symptoms\", []),\n",
    "            \"rca_analyses_list\": []\n",
    "        }\n",
    "        return [Send(\"supervisor_agent\", supervisor_input)]\n",
    "\n",
    "    parallel_rca_calls = []\n",
    "    for task in rca_tasks:\n",
    "        # Pass renamed fields to avoid InvalidUpdateError with parent state\n",
    "        rca_input_state = {\n",
    "            \"rca_task\": task,\n",
    "            \"rca_app_summary\": state.get(\"app_summary\", \"\"),  # Renamed field\n",
    "            \"rca_target_namespace\": state.get(\"target_namespace\", \"\"),  # Renamed field\n",
    "            \"messages\": [],\n",
    "            \"insights\": [],\n",
    "            \"prev_steps\": [],\n",
    "            \"rca_analyses_list\": []\n",
    "        }\n",
    "        parallel_rca_calls.append(Send(\"rca_agent\", rca_input_state))\n",
    "\n",
    "    return parallel_rca_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(SreParentState)\n",
    "\n",
    "builder.add_node(\"triage_agent\", triage_agent_graph)\n",
    "builder.add_node(\"planner_agent\", planner_agent_graph)\n",
    "builder.add_node(\"rca_agent\", rca_agent_graph)\n",
    "builder.add_node(\"supervisor_agent\", supervisor_agent_graph)\n",
    "\n",
    "builder.add_edge(START, \"triage_agent\")\n",
    "builder.add_edge(\"triage_agent\", \"planner_agent\")\n",
    "\n",
    "# Use rca_router to dynamically send tasks to parallel RCA agents\n",
    "# or skip to supervisor if no tasks\n",
    "builder.add_conditional_edges(\n",
    "    \"planner_agent\", \n",
    "    rca_router,\n",
    "    [\"rca_agent\", \"supervisor_agent\"]\n",
    ")\n",
    "\n",
    "# After RCA agents complete, go directly to supervisor (no collect_analyses needed)\n",
    "builder.add_edge(\"rca_agent\", \"supervisor_agent\")\n",
    "\n",
    "builder.add_edge(\"supervisor_agent\", END)\n",
    "\n",
    "parent_graph = builder.compile()\n",
    "Image(parent_graph.get_graph(xray=True).draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "async def run_sre_agent(graph, app_name: str, app_summary: str, target_namespace: str, trace_service_starting_point: str, trace_name: str | None = None):\n",
    "    \"\"\"Test the SRE agent workflow\"\"\"\n",
    "    \n",
    "    initial_state = {\n",
    "        \"app_name\": app_name,\n",
    "        \"app_summary\": app_summary,\n",
    "        \"target_namespace\": target_namespace,\n",
    "        \"trace_service_starting_point\": trace_service_starting_point,\n",
    "        \"problematic_pods\": {},\n",
    "        \"problematic_traces\": {},\n",
    "        \"slow_traces\": {},\n",
    "        \"problematic_metrics\": {},\n",
    "        \"symptoms\": [],\n",
    "        \"rca_tasks\": [],\n",
    "        \"rca_analyses_list\": [],  # Removed rca_analysis\n",
    "        \"final_report\": {}\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    config = {\"recursion_limit\": 100}\n",
    "    if trace_name:\n",
    "        config[\"run_name\"] = trace_name #type: ignore\n",
    "    \n",
    "    result = await graph.ainvoke(initial_state, config)\n",
    "    \n",
    "    execution_time = time.time() - start_time\n",
    "    \n",
    "    return result, execution_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = input(\"Enter experiment name: \")\n",
    "\n",
    "if experiment_name.strip() == \"\":\n",
    "    experiment_name = \"SRE Agent Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_summary = \"\"\"\n",
    "    The application implements a hotel reservation service, build with Go and gRPC. The initial project is extended in several ways, including adding back-end in-memory and persistent databases, adding a recommender system for obtaining hotel recommendations, and adding the functionality to place a hotel reservation. \n",
    "\"\"\"\n",
    "target_namespace = \"test-hotel-reservation\"\n",
    "service_starting_point = \"frontend\"\n",
    "\n",
    "result, exec_time = await run_sre_agent(\n",
    "    graph=parent_graph,\n",
    "    app_name=\"Hotel reservation\",\n",
    "    app_summary=app_summary,\n",
    "    target_namespace=target_namespace,\n",
    "    trace_service_starting_point=service_starting_point,\n",
    "    trace_name=experiment_name\n",
    ")\n",
    "\n",
    "print(f\"\\nExecution time: {exec_time:.2f} seconds\")\n",
    "print(f\"\\nFinal report:\\n{result.get('final_report', {})}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[\"final_report\"][\"root_cause\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result[\"rca_analyses_list\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_json_results(result: dict) -> dict:\n",
    "\n",
    "    export = result\n",
    "\n",
    "    # Convert symptom pydantic objects to dict\n",
    "    symptoms = []\n",
    "    for s in result[\"symptoms\"]:\n",
    "        symptoms.append(s.model_dump())\n",
    "    export[\"symptoms\"] = symptoms\n",
    "\n",
    "    # Convert rca_task pydantic objects to dict\n",
    "    rca_tasks = []\n",
    "    for t in result[\"rca_tasks\"]:\n",
    "        rca_tasks.append(t.model_dump())\n",
    "    export[\"rca_tasks\"] = rca_tasks\n",
    "    \n",
    "    return export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"sre_agent_result-new.json\", \"w\") as f:\n",
    "    exported_json = export_json_results(result)\n",
    "    json.dump(exported_json, f, indent=2, default=str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sre-agent-35UqMg2y-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
