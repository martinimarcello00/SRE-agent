{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0abb4d74",
   "metadata": {},
   "source": [
    "# RCA Agent\n",
    "\n",
    "The RCA agents take as input the affected resource, the symptom discovered by the triage agent and perform the Root Cause Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c93bd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# Get the path to the root directory of the repository\n",
    "root_dir = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
    "\n",
    "# Load environment variables from .env file in the root directory\n",
    "load_dotenv(os.path.join(root_dir, '.env'), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7af905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Add MCP-server to path\n",
    "mcp_server_path = os.path.abspath(os.path.join(os.getcwd(), '../../MCP-server'))\n",
    "sys.path.insert(0, mcp_server_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24889732",
   "metadata": {},
   "source": [
    "## MCP Server\n",
    "\n",
    "List of available MCP servers:\n",
    "- kubectl: provides an interface for the kubernetes cli\n",
    "- cluster_api: custom MCP server developed to interact with the cluster and see dependencies, traces and metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56e6afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "\n",
    "mcp_client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"kubernetes\" : {\n",
    "            \"command\": \"npx\",\n",
    "            \"args\": [\"mcp-server-kubernetes\"],\n",
    "            \"transport\": \"stdio\",\n",
    "            \"env\": {\n",
    "                \"ALLOW_ONLY_NON_DESTRUCTIVE_TOOLS\": \"true\"\n",
    "            }\n",
    "        },\n",
    "        \"cluster_api\" : {\n",
    "            \"url\": \"http://localhost:8000/mcp\",\n",
    "            \"transport\": \"streamable_http\"\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "mcp_tools = await mcp_client.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdc0516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools allowed\n",
    "k8s_tools_allowed = [\"kubectl_get\", \"kubectl_describe\", \"explain_resource\", \"list_api_resources\", \"ping\"]\n",
    "custom_tools_allowed = [\"get_metrics\", \"get_metrics_range\", \"get_pods_from_service\", \"get_cluster_pods_and_services\", \"get_services_used_by\", \"get_dependencies\", \"get_logs\", \"get_traces\", \"get_trace\"]\n",
    "\n",
    "tools_allowed = k8s_tools_allowed + custom_tools_allowed\n",
    "\n",
    "tools = []\n",
    "for tool in mcp_tools:\n",
    "    if tool.name in tools_allowed:\n",
    "        tools.append(tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd72fb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tool in tools:\n",
    "    print(f\"üîß {tool.name}: {tool.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6105af",
   "metadata": {},
   "source": [
    "## Build the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48235e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "gpt5mini = ChatOpenAI(model=\"gpt-5-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa5253e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import TypedDict, Literal, Annotated, List\n",
    "import operator\n",
    "\n",
    "class RCATask(BaseModel):\n",
    "    \"\"\"A RCA task to be performed by the RCA agent\"\"\"\n",
    "    investigation_goal: str = Field(..., description=\"Goal of the investigation\")\n",
    "    target_resource: str = Field(..., description=\"Name of the resource to investigate\")\n",
    "    resource_type: Literal[\"pod\", \"service\"] = Field(..., description=\"Type of resource being investigated\")\n",
    "    suggested_tools: List[str] = Field(default_factory=list, description=\"List of tools suggested for the investigation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553c1688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langgraph.graph.message import add_messages, AnyMessage\n",
    "\n",
    "class RcaAgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    app_summary: str\n",
    "    rca_task: RCATask\n",
    "    insights: Annotated[list[str], operator.add]\n",
    "    prev_steps: Annotated[list[str], operator.add]\n",
    "    rca_analysis: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6219ced2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpdateAgentData(BaseModel):\n",
    "    \"\"\"\n",
    "    Represents a step performed by the SRE agent.\n",
    "    \"\"\"\n",
    "    insight: str = Field(..., description=\"Most important new finding\")\n",
    "    prev_step: str = Field(..., description=\"Concise description of the most recent action taken\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f4a921",
   "metadata": {},
   "outputs": [],
   "source": [
    "rca_agent_prompt = \"\"\"\n",
    "    You are an expert DevOps engineer performing Root Cause Analysis on a Kubernetes service.\n",
    "\n",
    "    Service: {app_summary}\n",
    "\n",
    "    Investigation Task:\n",
    "    - **Goal**: {investigation_goal}\n",
    "    - **Target**: {resource_type} named '{target_resource}'\n",
    "    - **Suggested Tools**: {suggested_tools}\n",
    "\n",
    "    Your objective is to ACCOMPLISH the investigation goal by identifying the root cause that directly answers it.\n",
    "\n",
    "    Investigation Context:\n",
    "    *Previous Steps:* {prev_steps}\n",
    "    *Insights:* {insights}\n",
    "\n",
    "    Instructions:\n",
    "    1. Use available tools (kubectl, metrics, logs, traces, dependencies) to investigate the target resource\n",
    "    2. Follow the evidence trail to identify the root cause that explains the investigation goal\n",
    "    3. When you have sufficient evidence, call submit_final_diagnosis with:\n",
    "       - diagnosis: The root cause (must directly address the investigation goal)\n",
    "       - reasoning: How your diagnosis answers the investigation goal\n",
    "\n",
    "    IMPORTANT: Do not submit until your diagnosis directly explains what the investigation goal asked you to determine.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa3b311",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarise_prompt = \"\"\"\n",
    "    You are an autonomous SRE agent performing Root Cause Analysis on a Kubernetes incident.\n",
    "\n",
    "    Context:\n",
    "\n",
    "    Previous Insights: \n",
    "    {insights}\n",
    "    \n",
    "    Previous Steps:\n",
    "    {prev_steps}\n",
    "\n",
    "    Below are the latest messages (tool calls and/or tool responses - may include parallel executions):\n",
    "    {last_messages}\n",
    "\n",
    "    Instructions:\n",
    "    1. **Extract the key insight**: Identify the most important NEW finding from all the latest messages that helps diagnose the root cause. Focus on:\n",
    "       - Anomalies or unusual patterns\n",
    "       - Resource states that could cause issues\n",
    "       - Dependencies or relationships discovered\n",
    "       - Error messages or failure indicators\n",
    "       - Patterns across multiple tool responses (in case of parallel calls)\n",
    "       If the tool calls failed or returned no useful data, note this as the insight.\n",
    "    \n",
    "    2. **Describe the actions taken**: Write a concise description of what tools were called and what resources were examined.\n",
    "       Format: \"Checked [resource/metric] using [tool_name]\" (list all tools if multiple parallel calls)\n",
    "       Example for parallel: \"Checked pod logs and dependencies using get_logs and get_dependencies\"\n",
    "\n",
    "    Keep both responses under 150 characters each. Be specific and actionable.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90221147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_insights_str(state):\n",
    "    \"\"\"Return a string with the formatted list of insights gathered during exploration\"\"\"\n",
    "    if len(state[\"insights\"]) > 0:\n",
    "        return \"\\n- \".join([\"\"] + state[\"insights\"])\n",
    "    else:\n",
    "        return \"No insights yet\"\n",
    "    \n",
    "def get_prev_steps_str(state):\n",
    "    \"\"\"Return a string with the formatted list of previous steps performed during exploration\"\"\"\n",
    "    if len(state[\"prev_steps\"]) > 0:\n",
    "        return \"\\n- \".join([\"\"] + state[\"prev_steps\"])\n",
    "    else:\n",
    "        return \"No previous steps yet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b850a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_strct_output = gpt5mini.with_structured_output(UpdateAgentData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50db0573",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# Node used to summarise the infos given the latest messages (handles parallel tool calls)\n",
    "async def summarise(state: RcaAgentState):\n",
    "\n",
    "    # Gather all recent messages starting from the last AI message (tool calls)\n",
    "    # and all subsequent tool responses\n",
    "    messages = state[\"messages\"]\n",
    "    last_ai_idx = None\n",
    "    \n",
    "    # Find the last AI message (which contains tool calls)\n",
    "    for i in range(len(messages) - 1, -1, -1):\n",
    "        if isinstance(messages[i], AIMessage):\n",
    "            last_ai_idx = i\n",
    "            break\n",
    "    \n",
    "    # Collect messages from last AI message onwards (to capture all parallel responses)\n",
    "    if last_ai_idx is not None:\n",
    "        last_messages = messages[last_ai_idx:]\n",
    "    else:\n",
    "        last_messages = messages[-2:]  # Fallback to last 2 messages\n",
    "\n",
    "    insights_str = get_insights_str(state)\n",
    "    prev_step_str = get_prev_steps_str(state)\n",
    "\n",
    "    prompt = HumanMessage(content=summarise_prompt.format(\n",
    "        prev_steps = prev_step_str,\n",
    "        insights=insights_str,\n",
    "        last_messages=last_messages))\n",
    "\n",
    "    data = llm_with_strct_output.invoke([prompt])\n",
    "\n",
    "    return {\"insights\" : [data.insight], \"prev_steps\" : [data.prev_step]} #type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11ad610",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langgraph.types import Command\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.tools import tool, InjectedToolCallId\n",
    "\n",
    "#¬†Tool used to submit the final response\n",
    "@tool\n",
    "def submit_final_diagnosis(\n",
    "    diagnosis: str, \n",
    "    reasoning: str,\n",
    "    tool_call_id: Annotated[str, InjectedToolCallId]\n",
    ") -> Command:\n",
    "    \"\"\"\n",
    "    Submit the final diagnosis when investigation is complete.\n",
    "    \n",
    "    Args:\n",
    "        diagnosis: The issue you have identified (without fixing it)\n",
    "        reasoning: Your reasoning and thought process behind the diagnosis (keep it concise)\n",
    "    \n",
    "    Returns:\n",
    "        Command to update state and end workflow\n",
    "    \"\"\"\n",
    "    final_response = {\n",
    "        \"diagnosis\" : diagnosis,\n",
    "        \"reasoning\" : reasoning\n",
    "    }\n",
    "    \n",
    "    return Command(\n",
    "        update={\n",
    "            \"rca_analysis\": final_response,\n",
    "            \"messages\": [\n",
    "                ToolMessage(\n",
    "                    content=\"Final diagnosis submitted successfully. Investigation complete.\",\n",
    "                    tool_call_id=tool_call_id\n",
    "                )\n",
    "            ]\n",
    "        },\n",
    "        goto=\"format-output\" # End the loop cycle\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e04245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the tool for submission to the list of tools (MCP servers)\n",
    "completion_tool = submit_final_diagnosis\n",
    "tools_with_completion = tools + [completion_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc53573",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def rcaAgent(state: RcaAgentState):\n",
    "\n",
    "    insights_str = get_insights_str(state)\n",
    "    prev_step_str = get_prev_steps_str(state)\n",
    "    \n",
    "    # Extract task details\n",
    "    task = state[\"rca_task\"]\n",
    "    suggested_tools_str = \", \".join(task.suggested_tools) if task.suggested_tools else \"Use your best judgment\"\n",
    "\n",
    "    prompt = HumanMessage(content=rca_agent_prompt.format(\n",
    "        prev_steps=prev_step_str, \n",
    "        insights=insights_str, \n",
    "        app_summary=state[\"app_summary\"],\n",
    "        investigation_goal=task.investigation_goal,\n",
    "        resource_type=task.resource_type,\n",
    "        target_resource=task.target_resource,\n",
    "        suggested_tools=suggested_tools_str\n",
    "    ))\n",
    "\n",
    "    llm_with_completion_tools = gpt5mini.bind_tools(tools_with_completion, parallel_tool_calls=False)\n",
    "    return {\"messages\": [llm_with_completion_tools.invoke([prompt])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1c290e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "from collections import Counter\n",
    "\n",
    "def count_tool_calls(messages):\n",
    "    \"\"\"\n",
    "    Plots a bar chart of tool call occurrences by tool name from state['messages'].\n",
    "    \"\"\"\n",
    "    # Extract tool names from ToolMessage objects\n",
    "    tool_calls = []\n",
    "    for msg in messages:\n",
    "\n",
    "        if isinstance(msg, AIMessage):\n",
    "            if hasattr(msg, 'additional_kwargs'):\n",
    "                if \"tool_calls\" in msg.additional_kwargs:\n",
    "                    for call in msg.additional_kwargs['tool_calls']:\n",
    "                        if \"function\" in call:\n",
    "                            if \"name\" in call[\"function\"]:\n",
    "                                tool_calls.append(call[\"function\"][\"name\"])\n",
    "\n",
    "    # Count occurrences\n",
    "    counts = Counter(tool_calls)\n",
    "\n",
    "    return dict(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4739e225",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def format_response(state: RcaAgentState):\n",
    "\n",
    "    final_report = state[\"rca_analysis\"]\n",
    "    \n",
    "    task = state[\"rca_task\"]\n",
    "    final_report[\"task\"] = {\n",
    "        \"investigation_goal\" : task.investigation_goal,\n",
    "        \"target_resource\" : task.target_resource,\n",
    "        \"resource_type\" : task.resource_type,\n",
    "        \"suggested_tools\" : task.suggested_tools\n",
    "    }\n",
    "    \n",
    "    final_report[\"insights\"] = state[\"insights\"]\n",
    "    final_report[\"steps_performed\"] = state[\"prev_steps\"]\n",
    "    final_report[\"tools_stats\"] = count_tool_calls(state[\"messages\"])\n",
    "\n",
    "    return {\"rca_analysis\" : final_report}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7997d7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Build the graph\n",
    "builder = StateGraph(RcaAgentState)\n",
    "\n",
    "# Add nodes\n",
    "builder.add_node(\"rca-agent\", rcaAgent)\n",
    "builder.add_node(\"tools\", ToolNode(tools_with_completion)) # Tool node is executing the tool called in the previous message\n",
    "builder.add_node(\"summarise\", summarise) # Node to reduce the raw data into a schema\n",
    "builder.add_node(\"format-output\", format_response)\n",
    "\n",
    "# Add edges\n",
    "builder.add_edge(START, \"rca-agent\")\n",
    "\n",
    "# Conditional edge from sre-agent\n",
    "builder.add_conditional_edges(\n",
    "    \"rca-agent\",\n",
    "    # Use in the conditional_edge to route to the ToolNode if the last message has tool calls. Otherwise, route to the end.\n",
    "    tools_condition,\n",
    ")\n",
    "\n",
    "# After tools, decide whether to summarise or end\n",
    "def after_tools_condition(state: RcaAgentState):\n",
    "    # If rca analysis is filled, investigation is complete (end of the workflow)\n",
    "    if state.get(\"rca_analysis\") and \"diagnosis\" in state[\"rca_analysis\"] and \"reasoning\" in state[\"rca_analysis\"]:\n",
    "        return \"format-output\"\n",
    "    return \"summarise\"\n",
    "\n",
    "builder.add_conditional_edges(\n",
    "    \"tools\",\n",
    "    after_tools_condition,\n",
    "    {\n",
    "        \"summarise\": \"summarise\",\n",
    "        \"format-output\": \"format-output\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# After summarise, continue investigation (go to rca-agent)\n",
    "builder.add_edge(\"summarise\", \"rca-agent\")\n",
    "builder.add_edge(\"format-output\", END)\n",
    "\n",
    "# Compile the graph\n",
    "structured_graph = builder.compile()\n",
    "\n",
    "# Show the graph\n",
    "display(Image(structured_graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f735a582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "async def test_structured_graph(graph, app_summary: str, rca_task: RCATask, human_message: str = \"\", trace_name: str | None = None):\n",
    "    \"\"\"Test the structured graph with RcaAgentState\"\"\"\n",
    "    # Create initial state with RcaAgentState structure\n",
    "    initial_state = {\n",
    "        \"messages\": [HumanMessage(content=human_message)] if human_message else [],\n",
    "        \"rca_task\" : rca_task,\n",
    "        \"insights\": [],\n",
    "        \"prev_steps\": [],\n",
    "        \"rca_analysis\" : {},\n",
    "        \"app_summary\" : app_summary\n",
    "    }\n",
    "    \n",
    "    # Start time tracking\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Configuration for the graph execution\n",
    "    config = {\"recursion_limit\": 50}\n",
    "    if trace_name:\n",
    "        config[\"run_name\"] = trace_name # type: ignore\n",
    "    \n",
    "    # Invoke the graph asynchronously\n",
    "    result = await graph.ainvoke(initial_state, config)\n",
    "\n",
    "    # Calculate execution time\n",
    "    execution_time = time.time() - start_time\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17f3ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = input(\"Enter experiment name: \")\n",
    "\n",
    "if experiment_name.strip() == \"\":\n",
    "    experiment_name = \"RCA agent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a950f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_summary = \"\"\"\n",
    "    The application implements a hotel reservation service, build with Go and gRPC. The initial project is extended in several ways, including adding back-end in-memory and persistent databases, adding a recommender system for obtaining hotel recommendations, and adding the functionality to place a hotel reservation. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea1415d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rca_task = RCATask(\n",
    "    investigation_goal=\"Collect recent stdout/stderr logs from the 'hotel-reserv-geo' container in pod geo-6b4b89b5f5-rsrh7 to identify the runtime error(s) that produced exit_code=2 and triggered restarts.\",\n",
    "    target_resource=\"geo-6b4b89b5f5-rsrh7\",\n",
    "    resource_type=\"pod\",\n",
    "    suggested_tools=[\"get_logs\", \"get_traces\", \"get_metrics_range\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae33efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "human = \"\"\n",
    "rca_agent_output = await test_structured_graph(structured_graph, app_summary, rca_task, trace_name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53260442",
   "metadata": {},
   "outputs": [],
   "source": [
    "rca_agent_output[\"rca_analysis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289f55db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "def display_rca_analysis(rca_analysis):\n",
    "    \"\"\"Display RCA analysis in a formatted markdown\"\"\"\n",
    "    \n",
    "    md = f\"\"\"\n",
    "# üîç Root Cause Analysis Report\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Investigation Task\n",
    "\n",
    "**Goal:** {rca_analysis['task']['investigation_goal']}  \n",
    "**Resource Type:** {rca_analysis['task']['resource_type']}  \n",
    "**Target Resource:** `{rca_analysis['task']['target_resource']}`\n",
    "\n",
    "**Suggested Tools:**\n",
    "- {', '.join(rca_analysis['task']['suggested_tools']) if rca_analysis['task']['suggested_tools'] else 'None'}\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Diagnosis\n",
    "\n",
    "{rca_analysis['diagnosis']}\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Reasoning\n",
    "\n",
    "{rca_analysis['reasoning']}\n",
    "\n",
    "---\n",
    "\n",
    "## üîé Investigation Details\n",
    "\n",
    "### Steps Performed ({len(rca_analysis['steps_performed'])} steps)\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    for i, step in enumerate(rca_analysis['steps_performed'], 1):\n",
    "        md += f\"{i}. {step}\\n\"\n",
    "    \n",
    "    md += \"\\n### Key Insights\\n\\n\"\n",
    "    \n",
    "    for i, insight in enumerate(rca_analysis['insights'], 1):\n",
    "        md += f\"{i}. {insight}\\n\"\n",
    "    \n",
    "    md += \"\\n---\\n\\n## üìä Tool Usage Statistics\\n\\n\"\n",
    "    \n",
    "    total_calls = sum(rca_analysis['tools_stats'].values())\n",
    "    md += f\"**Total Tool Calls:** {total_calls}\\n\\n\"\n",
    "    \n",
    "    for tool, count in sorted(rca_analysis['tools_stats'].items(), key=lambda x: x[1], reverse=True):\n",
    "        md += f\"- `{tool}`: ({count})\\n\"\n",
    "    \n",
    "    return Markdown(md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c2a3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(display_rca_analysis(rca_agent_output[\"rca_analysis\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35fe510",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in rca_agent_output['messages']:\n",
    "    m.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sre-agent-35UqMg2y-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
